{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB\n",
    "* meta feature: 불용어 개수, 단어 개수, 문장 부호 개수\n",
    "* text feature: 단어 등장 빈도 수 word2vec 문장 자체에서 추출한 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17556, 22)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "preprocessing_data = pd.read_pickle(\"final_data_end_0429.pkl\")\n",
    "preprocessing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanspell_content = pd.read_pickle(\"end_hanspell.pkl\")  # 데이터 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40054, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "origin_data = pd.read_pickle(\"../../petition/petition_total_data.pkl\")\n",
    "origin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code', 'sdays', 'edays', 'title', 'count', 'content', 'category',\n",
       "       'progress', 'link', 'person'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(preprocessing_data, origin_data[['code','content']], how = 'inner', on = ['code'])\n",
    "data = pd.merge(data, hanspell_content[['code','pre_content']], how = 'inner', on = 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "title                  0\n",
       "count                  0\n",
       "content_x              0\n",
       "category               0\n",
       "progress               0\n",
       "summary_content_end    0\n",
       "title_len              0\n",
       "doc_len                0\n",
       "content_noun           0\n",
       "content_verb           0\n",
       "content_adj            0\n",
       "sdays                  0\n",
       "edays                  0\n",
       "emotion                0\n",
       "title_token            0\n",
       "total_token            0\n",
       "top_keyword            0\n",
       "count_noun             0\n",
       "count_verb             0\n",
       "count_adj              0\n",
       "target                 0\n",
       "content_y              0\n",
       "pre_content            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "data = data[data['sdays']<datetime.datetime.strptime(\"2021.03.01\",\"%Y.%m.%d\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-01 00:00:00\n",
      "2021-03-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(origin_data['sdays'].min())\n",
    "print(origin_data['sdays'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-01 00:00:00\n",
      "2021-03-19 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing_data['sdays'].min())\n",
    "print(preprocessing_data['sdays'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-01 00:00:00\n",
      "2021-02-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data['sdays'].min())\n",
    "print(data['sdays'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['count'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "      <th>content_x</th>\n",
       "      <th>category</th>\n",
       "      <th>progress</th>\n",
       "      <th>summary_content_end</th>\n",
       "      <th>title_len</th>\n",
       "      <th>doc_len</th>\n",
       "      <th>content_noun</th>\n",
       "      <th>...</th>\n",
       "      <th>emotion</th>\n",
       "      <th>title_token</th>\n",
       "      <th>total_token</th>\n",
       "      <th>top_keyword</th>\n",
       "      <th>count_noun</th>\n",
       "      <th>count_verb</th>\n",
       "      <th>count_adj</th>\n",
       "      <th>target</th>\n",
       "      <th>content_y</th>\n",
       "      <th>pre_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>586819</td>\n",
       "      <td>텔레그램 n번방 용의자 신상공개 및 포토라인 세워주세요</td>\n",
       "      <td>2715626.0</td>\n",
       "      <td>오늘 검거되었다고 합니다타인의 수치심과 어린 학생들을지옥으로 몰아넣은 가해자를포토라...</td>\n",
       "      <td>안전/환경</td>\n",
       "      <td>답변완료</td>\n",
       "      <td>오늘 검거되었다고 합니다 타인의 수치심과 어린 학생들을 지옥으로 몰아넣은 가해자를 ...</td>\n",
       "      <td>30</td>\n",
       "      <td>306</td>\n",
       "      <td>[오늘, 검거, 합, 니다, 타인, 수치심, 학생, 지옥, 가해자, 포토, 라인, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>dontknow</td>\n",
       "      <td>[텔레그램, 번, 방, 용의자, 신상, 공개, 포토, 라인]</td>\n",
       "      <td>[텔레그램, 번, 방, 용의자, 신상, 공개, 포토, 라인, 오늘, 검거, 합, 니...</td>\n",
       "      <td>{'포토': 0.497, '라인': 0.358, '악마': 0.256, '수치심':...</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>오늘 검거되었다고 합니다타인의 수치심과 어린 학생들을지옥으로 몰아넣은 가해자를포토라...</td>\n",
       "      <td>오늘 검거되었다고 합니다 타인의 수치심과 어린 학생들을 지옥으로 몰아넣은 가해자를 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      code                           title      count  \\\n",
       "62  586819  텔레그램 n번방 용의자 신상공개 및 포토라인 세워주세요  2715626.0   \n",
       "\n",
       "                                            content_x category progress  \\\n",
       "62  오늘 검거되었다고 합니다타인의 수치심과 어린 학생들을지옥으로 몰아넣은 가해자를포토라...    안전/환경    답변완료    \n",
       "\n",
       "                                  summary_content_end  title_len  doc_len  \\\n",
       "62  오늘 검거되었다고 합니다 타인의 수치심과 어린 학생들을 지옥으로 몰아넣은 가해자를 ...         30      306   \n",
       "\n",
       "                                         content_noun  ...   emotion  \\\n",
       "62  [오늘, 검거, 합, 니다, 타인, 수치심, 학생, 지옥, 가해자, 포토, 라인, ...  ...  dontknow   \n",
       "\n",
       "                          title_token  \\\n",
       "62  [텔레그램, 번, 방, 용의자, 신상, 공개, 포토, 라인]   \n",
       "\n",
       "                                          total_token  \\\n",
       "62  [텔레그램, 번, 방, 용의자, 신상, 공개, 포토, 라인, 오늘, 검거, 합, 니...   \n",
       "\n",
       "                                          top_keyword count_noun count_verb  \\\n",
       "62  {'포토': 0.497, '라인': 0.358, '악마': 0.256, '수치심':...         56         12   \n",
       "\n",
       "   count_adj target                                          content_y  \\\n",
       "62         2      1  오늘 검거되었다고 합니다타인의 수치심과 어린 학생들을지옥으로 몰아넣은 가해자를포토라...   \n",
       "\n",
       "                                          pre_content  \n",
       "62  오늘 검거되었다고 합니다 타인의 수치심과 어린 학생들을 지옥으로 몰아넣은 가해자를 ...  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['count'] == data['count'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'] = pd.to_numeric(data['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_lst = []\n",
    "for x in data['count']:\n",
    "    if x < 200000:\n",
    "        count_lst.append(0)\n",
    "    else:\n",
    "        count_lst.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = count_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 300, 600, 1500, 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata['target'] = pd.qcut(data['count'],5, labels = [0,1,2,3,4])\\n\\nfor i in range(len(data)):\\n    if data['count'][i] < 300 :\\n        data['target'][i] = 0\\n    if data['count'][i] >= 300 and data['count'][i] < 600 :\\n        data['target'][i] = 1\\n    if data['count'][i] >= 600 and data['count'][i] < 1200:\\n        data['target'][i] = 2\\n    if data['count'][i] >= 1200 and data['count'][i] < 4000:\\n        data['target'][i] = 3\\n    if data['count'][i] >= 4000:\\n        data['target'][i] = 4\\n        \\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data['target'] = pd.qcut(data['count'],5, labels = [0,1,2,3,4])\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if data['count'][i] < 300 :\n",
    "        data['target'][i] = 0\n",
    "    if data['count'][i] >= 300 and data['count'][i] < 600 :\n",
    "        data['target'][i] = 1\n",
    "    if data['count'][i] >= 600 and data['count'][i] < 1200:\n",
    "        data['target'][i] = 2\n",
    "    if data['count'][i] >= 1200 and data['count'][i] < 4000:\n",
    "        data['target'][i] = 3\n",
    "    if data['count'][i] >= 4000:\n",
    "        data['target'][i] = 4\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17033\n",
       "1      136\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     190997.0\n",
       "1    2715626.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['target'])['count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "title                  0\n",
       "count                  0\n",
       "content_x              0\n",
       "category               0\n",
       "progress               0\n",
       "summary_content_end    0\n",
       "title_len              0\n",
       "doc_len                0\n",
       "content_noun           0\n",
       "content_verb           0\n",
       "content_adj            0\n",
       "sdays                  0\n",
       "edays                  0\n",
       "emotion                0\n",
       "title_token            0\n",
       "total_token            0\n",
       "top_keyword            0\n",
       "count_noun             0\n",
       "count_verb             0\n",
       "count_adj              0\n",
       "target                 0\n",
       "content_y              0\n",
       "pre_content            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['count']>=data['count'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = data[data['target']==0]\n",
    "data_1 = data[data['target']!=0]\n",
    "\n",
    "data_0 = data_0.sample(n=1000, random_state = 42)\n",
    "final_data = pd.concat([data_0, data_1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.get_dummies(final_data,columns = ['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(final_data, test_size = 0.2, stratify = final_data['target'],shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    799\n",
       "1    109\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "title                  0\n",
       "count                  0\n",
       "content_x              0\n",
       "category               0\n",
       "progress               0\n",
       "summary_content_end    0\n",
       "title_len              0\n",
       "doc_len                0\n",
       "content_noun           0\n",
       "content_verb           0\n",
       "content_adj            0\n",
       "sdays                  0\n",
       "edays                  0\n",
       "title_token            0\n",
       "total_token            0\n",
       "top_keyword            0\n",
       "count_noun             0\n",
       "count_verb             0\n",
       "count_adj              0\n",
       "target                 0\n",
       "content_y              0\n",
       "pre_content            0\n",
       "emotion_angry          0\n",
       "emotion_disgust        0\n",
       "emotion_dontknow       0\n",
       "emotion_fear           0\n",
       "emotion_sad            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용할 feature 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of words in the text ##\n",
    "train_df[\"num_words\"] = train_df[\"pre_content\"].apply(lambda x: len(str(x).split()))\n",
    "test_df[\"num_words\"] = test_df[\"pre_content\"].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of unique words in the text ##\n",
    "train_df[\"num_unique_words\"] = train_df[\"pre_content\"].apply(lambda x: len(set(str(x).split())))\n",
    "test_df[\"num_unique_words\"] = test_df[\"pre_content\"].apply(lambda x: len(set(str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기호 개수 \n",
    "import string\n",
    "train_df[\"num_punctuations\"] =train_df['content_y'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test_df[\"num_punctuations\"] =test_df['content_y'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 단어 개수 \n",
    "train_df[\"mean_word_len\"] = train_df[\"pre_content\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"mean_word_len\"] = test_df[\"pre_content\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 단어 개수 \n",
    "train_df[\"title_mean_word_len\"] = train_df[\"title\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"title_mean_word_len\"] = test_df[\"title\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##additional\n",
    "train_df[\",\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\n",
    "test_df[\",\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\n",
    "\n",
    "train_df[\";\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\n",
    "test_df[\";\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\n",
    "\n",
    "train_df['\\\"'] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\n",
    "test_df['\\\"'] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\n",
    "\n",
    "train_df[\"...\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\n",
    "test_df[\"...\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\n",
    "\n",
    "train_df[\"?\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\n",
    "test_df[\"?\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\n",
    "\n",
    "train_df[\"!\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\n",
    "test_df[\"!\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\n",
    "\n",
    "train_df[\".\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\n",
    "test_df[\".\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\n",
    "\n",
    "train_df[\":\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\n",
    "test_df[\":\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\n",
    "\n",
    "train_df[\"*\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\n",
    "test_df[\"*\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\n",
    "\n",
    "train_df[\"-\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))\n",
    "test_df[\"-\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))\n",
    "\n",
    "train_df[\"■\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"■\")]))\n",
    "test_df[\"■\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"■\")]))\n",
    "\n",
    "train_df[\"★\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"★\")]))\n",
    "test_df[\"★\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"★\")]))\n",
    "\n",
    "train_df[\"@\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"@\")]))\n",
    "test_df[\"@\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"@\")]))\n",
    "\n",
    "\n",
    "train_df[\"please\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"부탁\")]))\n",
    "test_df[\"please\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"부탁\")]))\n",
    "\n",
    "\n",
    "train_df[\"chu\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"청원\")]))\n",
    "test_df[\"chu\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"청원\")]))\n",
    "\n",
    "\n",
    "train_df[\"moon\"] = train_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"대통령\")]))\n",
    "test_df[\"moon\"] = test_df[\"content_y\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"대통령\")]))\n",
    "\n",
    "train_df[\"log_doc\"] = np.log(train_df[\"doc_len\"])\n",
    "test_df[\"log_doc\"] = np.log(test_df[\"doc_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"count_noun\"] = np.sqrt(train_df[\"count_noun\"])\n",
    "train_df[\"count_verb\"] = np.sqrt(train_df[\"count_verb\"])\n",
    "train_df[\"count_adj\"] = np.sqrt(train_df[\"count_adj\"])\n",
    "\n",
    "\n",
    "test_df[\"count_noun\"] = np.sqrt(test_df[\"count_noun\"])\n",
    "test_df[\"count_verb\"] = np.sqrt(test_df[\"count_verb\"])\n",
    "test_df[\"count_adj\"] = np.sqrt(test_df[\"count_adj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "title                  0\n",
       "count                  0\n",
       "content_x              0\n",
       "category               0\n",
       "progress               0\n",
       "summary_content_end    0\n",
       "title_len              0\n",
       "doc_len                0\n",
       "content_noun           0\n",
       "content_verb           0\n",
       "content_adj            0\n",
       "sdays                  0\n",
       "edays                  0\n",
       "title_token            0\n",
       "total_token            0\n",
       "top_keyword            0\n",
       "count_noun             0\n",
       "count_verb             0\n",
       "count_adj              0\n",
       "target                 0\n",
       "content_y              0\n",
       "pre_content            0\n",
       "emotion_angry          0\n",
       "emotion_disgust        0\n",
       "emotion_dontknow       0\n",
       "emotion_fear           0\n",
       "emotion_sad            0\n",
       "num_words              0\n",
       "num_unique_words       0\n",
       "num_punctuations       0\n",
       "mean_word_len          0\n",
       "title_mean_word_len    0\n",
       ",                      0\n",
       ";                      0\n",
       "\"                      0\n",
       "...                    0\n",
       "?                      0\n",
       "!                      0\n",
       ".                      0\n",
       ":                      0\n",
       "*                      0\n",
       "-                      0\n",
       "■                      0\n",
       "★                      0\n",
       "@                      0\n",
       "please                 0\n",
       "chu                    0\n",
       "moon                   0\n",
       "log_doc                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "title                  0\n",
       "count                  0\n",
       "content_x              0\n",
       "category               0\n",
       "progress               0\n",
       "summary_content_end    0\n",
       "title_len              0\n",
       "doc_len                0\n",
       "content_noun           0\n",
       "content_verb           0\n",
       "content_adj            0\n",
       "sdays                  0\n",
       "edays                  0\n",
       "title_token            0\n",
       "total_token            0\n",
       "top_keyword            0\n",
       "count_noun             0\n",
       "count_verb             0\n",
       "count_adj              0\n",
       "target                 0\n",
       "content_y              0\n",
       "pre_content            0\n",
       "emotion_angry          0\n",
       "emotion_disgust        0\n",
       "emotion_dontknow       0\n",
       "emotion_fear           0\n",
       "emotion_sad            0\n",
       "num_words              0\n",
       "num_unique_words       0\n",
       "num_punctuations       0\n",
       "mean_word_len          0\n",
       "title_mean_word_len    0\n",
       ",                      0\n",
       ";                      0\n",
       "\"                      0\n",
       "...                    0\n",
       "?                      0\n",
       "!                      0\n",
       ".                      0\n",
       ":                      0\n",
       "*                      0\n",
       "-                      0\n",
       "■                      0\n",
       "★                      0\n",
       "@                      0\n",
       "please                 0\n",
       "chu                    0\n",
       "moon                   0\n",
       "log_doc                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "      <th>content_x</th>\n",
       "      <th>category</th>\n",
       "      <th>progress</th>\n",
       "      <th>summary_content_end</th>\n",
       "      <th>title_len</th>\n",
       "      <th>doc_len</th>\n",
       "      <th>content_noun</th>\n",
       "      <th>content_verb</th>\n",
       "      <th>content_adj</th>\n",
       "      <th>sdays</th>\n",
       "      <th>edays</th>\n",
       "      <th>title_token</th>\n",
       "      <th>total_token</th>\n",
       "      <th>top_keyword</th>\n",
       "      <th>count_noun</th>\n",
       "      <th>count_verb</th>\n",
       "      <th>count_adj</th>\n",
       "      <th>target</th>\n",
       "      <th>content_y</th>\n",
       "      <th>pre_content</th>\n",
       "      <th>emotion_angry</th>\n",
       "      <th>emotion_disgust</th>\n",
       "      <th>emotion_dontknow</th>\n",
       "      <th>emotion_fear</th>\n",
       "      <th>emotion_sad</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>title_mean_word_len</th>\n",
       "      <th>,</th>\n",
       "      <th>;</th>\n",
       "      <th>\"</th>\n",
       "      <th>...</th>\n",
       "      <th>?</th>\n",
       "      <th>!</th>\n",
       "      <th>.</th>\n",
       "      <th>:</th>\n",
       "      <th>*</th>\n",
       "      <th>-</th>\n",
       "      <th>■</th>\n",
       "      <th>★</th>\n",
       "      <th>@</th>\n",
       "      <th>please</th>\n",
       "      <th>chu</th>\n",
       "      <th>moon</th>\n",
       "      <th>log_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>589340</td>\n",
       "      <td>용산 정비창 부지 8,000호 주택공급 계획에 대한 재검토 요청</td>\n",
       "      <td>494.0</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>35</td>\n",
       "      <td>2170</td>\n",
       "      <td>[최근, 용산정, 비창, 부지, 주택, 세대, 건립, 계획, 발표, 여론, 형성, ...</td>\n",
       "      <td>[있, 보, 보, 앞서, 내세우, 되, 나아가, 통하, 돌아가, 엮이, 있, 갚, ...</td>\n",
       "      <td>[없, 같, 같, 뛰어나, 가깝, 없, 그렇, 많, 어떻, 아름답, 많, 없, 귀하...</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>[용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청]</td>\n",
       "      <td>[용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청, 최근, 용산...</td>\n",
       "      <td>{'용산': 0.391, '국제': 0.31, '입지': 0.266, '부지': 0...</td>\n",
       "      <td>18.654758</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>0</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>439</td>\n",
       "      <td>62</td>\n",
       "      <td>3.165703</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>97.681818</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000</td>\n",
       "      <td>216.100</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>66.843750</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>1084.500000</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>7.682482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11931</th>\n",
       "      <td>591390</td>\n",
       "      <td>양육비 대지급제 시행을 촉구합니다</td>\n",
       "      <td>362.0</td>\n",
       "      <td>저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>저는 남편의 불륜으로 이혼 예정인 워킹맘입니다 사춘기 아이 둘을 둔 엄마이기도 합니...</td>\n",
       "      <td>18</td>\n",
       "      <td>1338</td>\n",
       "      <td>[남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아이, 엄마, 그간, 남편, 불륜,...</td>\n",
       "      <td>[두, 덮, 모르, 위하, 지키, 속이, 있, 걸, 헤어지, 끊, 돌아오, 보, 참...</td>\n",
       "      <td>[그렇, 크, 없, 어떻, 없, 어렵, 없, 어떻]</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>[양육비, 대지급, 시행, 촉구]</td>\n",
       "      <td>[양육비, 대지급, 시행, 촉구, 남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아...</td>\n",
       "      <td>{'양육비': 0.52, '한부모': 0.441, '이혼': 0.213, '불륜':...</td>\n",
       "      <td>14.106736</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0</td>\n",
       "      <td>저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....</td>\n",
       "      <td>저는 남편의 불륜으로 이혼 예정인 워킹맘입니다. 사춘기 아이 둘을 둔 엄마이기도 합...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>290</td>\n",
       "      <td>44</td>\n",
       "      <td>3.128280</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>332.250</td>\n",
       "      <td>166.375</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>37.257143</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>7.198931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>588168</td>\n",
       "      <td>특수상권의 자영업자는 두번 죽습니다.</td>\n",
       "      <td>205.0</td>\n",
       "      <td>아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다 매출이 반 토막보다 더...</td>\n",
       "      <td>20</td>\n",
       "      <td>291</td>\n",
       "      <td>[음식점, 업, 상공, 자영업자, 매출, 토막, 수준, 사정, 국민, 모두, 조금,...</td>\n",
       "      <td>[있, 더하, 줄어들, 그러, 참, 버티, 버티, 되, 찾, 죽이, 처하]</td>\n",
       "      <td>[힘들, 힘들, 같, 같, 작, 힘들]</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>[특수, 상권, 자영업자, 번]</td>\n",
       "      <td>[특수, 상권, 자영업자, 번, 음식점, 업, 상공, 자영업자, 매출, 토막, 수준...</td>\n",
       "      <td>{'매장': 0.52, '상공': 0.384, '특수': 0.369, '자영업자':...</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0</td>\n",
       "      <td>아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...</td>\n",
       "      <td>아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다. 매출이 반 토막보다 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>3.138889</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>5.673323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16730</th>\n",
       "      <td>596255</td>\n",
       "      <td>\"가야고분군\" 세계유산 등재신청에서 남원 유곡리와 두락리고분군은 제외하여 주십시요</td>\n",
       "      <td>128.0</td>\n",
       "      <td>문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...</td>\n",
       "      <td>문화/예술/체육/언론</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...</td>\n",
       "      <td>45</td>\n",
       "      <td>2278</td>\n",
       "      <td>[문재인, 대통령, 9월 10일, 문화재, 청, 문화재, 위원회, 세계유산, 분, ...</td>\n",
       "      <td>[지나, 지니, 되, 반하, 여기, 지나, 나타나, 보이, 두, 보, 맞, 이루, ...</td>\n",
       "      <td>[크, 많, 그렇, 다르, 없, 그렇, 넓, 좋, 멀, 안타깝, 없]</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>[가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...</td>\n",
       "      <td>[가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...</td>\n",
       "      <td>{'가야': 0.589, '남원': 0.327, '백제': 0.302, '등재': ...</td>\n",
       "      <td>20.663978</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0</td>\n",
       "      <td>문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...</td>\n",
       "      <td>문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>417</td>\n",
       "      <td>55</td>\n",
       "      <td>3.281310</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>107.523810</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>454.800000</td>\n",
       "      <td>2278.000</td>\n",
       "      <td>2278.000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>125.611111</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>568.750000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>453.200000</td>\n",
       "      <td>7.731053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>584120</td>\n",
       "      <td>국가어항 슬롭웨이 만큼은 레져보트인이 사용할수 있게 해주세요</td>\n",
       "      <td>552.0</td>\n",
       "      <td>우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...</td>\n",
       "      <td>농산어촌</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며  그로 인해 레저보트 산업...</td>\n",
       "      <td>33</td>\n",
       "      <td>653</td>\n",
       "      <td>[우리나라, 레져, 보트, 낚시, 인구, 급속, 증가, 추세, 레져, 보트, 산업,...</td>\n",
       "      <td>[인하, 되, 위하, 되, 있, 있, 즐기, 있, 있, 대하, 갖, 가, 대하, 쌓...</td>\n",
       "      <td>[시, 없, 시]</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>[국가, 어항, 만큼, 레져, 보트, 인, 사용]</td>\n",
       "      <td>[국가, 어항, 만큼, 레져, 보트, 인, 사용, 우리나라, 레져, 보트, 낚시, ...</td>\n",
       "      <td>{'레져': 0.6, '보트': 0.587, '낚시': 0.152, '어민': 0....</td>\n",
       "      <td>10.583005</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0</td>\n",
       "      <td>우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...</td>\n",
       "      <td>우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며. 그로 인해 레저보트 산업...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>131</td>\n",
       "      <td>21</td>\n",
       "      <td>3.084967</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000</td>\n",
       "      <td>653.000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>92.428571</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>325.500000</td>\n",
       "      <td>325.500000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>6.481577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>593979</td>\n",
       "      <td>놀다 친구와 부딪힌 사고로 우리집의 6살 슈퍼히어로가 하늘나라로 출동했습니다. 어린...</td>\n",
       "      <td>206063.0</td>\n",
       "      <td>10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>답변완료</td>\n",
       "      <td>10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>96</td>\n",
       "      <td>4083</td>\n",
       "      <td>[10월 21일, 수요일, 회사, 점심, 식사, 후, 커피, 아이, 어린이집, 전화...</td>\n",
       "      <td>[마시, 있, 부딪히, 울, 되, 졸, 자, 일어나, 먹, 토하, 흘리, 가, 보,...</td>\n",
       "      <td>[크, 짧, 같, 적, 적, 없, 이렇, 어떻, 크, 많, 없, 괜찮, 같, 힘들,...</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>2020-12-13</td>\n",
       "      <td>[친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...</td>\n",
       "      <td>[친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...</td>\n",
       "      <td>{'어린이집': 0.471, '교사': 0.341, '세바': 0.286, '보육'...</td>\n",
       "      <td>23.937418</td>\n",
       "      <td>12.961481</td>\n",
       "      <td>6.708204</td>\n",
       "      <td>1</td>\n",
       "      <td>10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "      <td>762</td>\n",
       "      <td>152</td>\n",
       "      <td>2.898386</td>\n",
       "      <td>3.409091</td>\n",
       "      <td>51.358974</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>4083.000</td>\n",
       "      <td>4083.000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>76.056604</td>\n",
       "      <td>2041.000000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>679.666667</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>2040.500000</td>\n",
       "      <td>2040.500000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>8.314587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>589634</td>\n",
       "      <td>'저의 딸이 강간 당하는 것을 목격하여..'  그 충격과 고통으로 딸이 평생 남을 ...</td>\n",
       "      <td>286148.0</td>\n",
       "      <td>국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...</td>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>답변완료</td>\n",
       "      <td>국민청원 사유 저는 성폭행 당한 딸의 엄마입니다 그냥 피눈물이 주르륵 납니다  저의...</td>\n",
       "      <td>98</td>\n",
       "      <td>10232</td>\n",
       "      <td>[국민, 사유, 성폭행, 딸, 엄마, 피눈물, 딸, 성폭행, 목격, 사건, 분, 본...</td>\n",
       "      <td>[당하, 나, 당하, 덮, 묻, 당하, 덮, 저지르, 저지르, 있, 위하, 넘어가,...</td>\n",
       "      <td>[많, 없, 그렇, 못되, 못되, 없, 아프, 없, 어이없, 못되, 그렇, 뻔하, ...</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>2020-07-11</td>\n",
       "      <td>[딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...</td>\n",
       "      <td>[딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...</td>\n",
       "      <td>{'증거': 0.285, '진술': 0.283, '가해자': 0.282, '성폭행'...</td>\n",
       "      <td>39.458839</td>\n",
       "      <td>16.643317</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>1</td>\n",
       "      <td>국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...</td>\n",
       "      <td>국민청원 사유 저는 성폭행 당한 딸의 엄마입니다. 그냥 피눈물이 주르륵 납니다. 저...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2417</td>\n",
       "      <td>1254</td>\n",
       "      <td>576</td>\n",
       "      <td>2.927596</td>\n",
       "      <td>3.217391</td>\n",
       "      <td>111.450549</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>10232.000000</td>\n",
       "      <td>1276.375</td>\n",
       "      <td>681.200</td>\n",
       "      <td>351.862069</td>\n",
       "      <td>80.214286</td>\n",
       "      <td>408.320000</td>\n",
       "      <td>261.384615</td>\n",
       "      <td>291.371429</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>600.941176</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>2044.800000</td>\n",
       "      <td>3409.333333</td>\n",
       "      <td>1702.833333</td>\n",
       "      <td>9.233275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>583065</td>\n",
       "      <td>신기술의 거부감으로 인한 구시대의 규제를 완화하여 주십시요</td>\n",
       "      <td>218.0</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...</td>\n",
       "      <td>성장동력</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...</td>\n",
       "      <td>32</td>\n",
       "      <td>3250</td>\n",
       "      <td>[국민, 요지, 특허청, 특허, 심사, 진행, 심사, 관, 특허, 명세서, 과학, ...</td>\n",
       "      <td>[않, 되, 인하, 있, 인하, 대하, 있, 대하, 대하, 있, 달, 있, 대하, ...</td>\n",
       "      <td>[없, 안타깝, 어렵, 크, 없, 없, 많, 없, 없, 없, 없, 많, 없, 없]</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>[신기술, 거부감, 시대, 규제, 완화]</td>\n",
       "      <td>[신기술, 거부감, 시대, 규제, 완화, 국민, 요지, 특허청, 특허, 심사, 진행...</td>\n",
       "      <td>{'심사': 0.402, '특허': 0.397, '특허청': 0.354, '기술':...</td>\n",
       "      <td>23.853721</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>457</td>\n",
       "      <td>151</td>\n",
       "      <td>3.526685</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>55.051724</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>360.222222</td>\n",
       "      <td>3250.000</td>\n",
       "      <td>3250.000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>84.552632</td>\n",
       "      <td>1082.666667</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>170.105263</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>8.086410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14743</th>\n",
       "      <td>594239</td>\n",
       "      <td>농협비리를 고발합니다</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...</td>\n",
       "      <td>농산어촌</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...</td>\n",
       "      <td>11</td>\n",
       "      <td>1541</td>\n",
       "      <td>[해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, 농사, 재배, 농민, ...</td>\n",
       "      <td>[있, 있, 있, 떠나, 가지, 있, 도와주, 드리, 묻, 따르, 막히, 들추, 지...</td>\n",
       "      <td>[어렵, 낮, 기막히, 없, 없, 싫, 없, 수많]</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>[농협, 비리, 고발]</td>\n",
       "      <td>[농협, 비리, 고발, 해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, ...</td>\n",
       "      <td>{'농협': 0.453, '조합장': 0.449, '농민': 0.383, '운영':...</td>\n",
       "      <td>16.278821</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0</td>\n",
       "      <td>저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...</td>\n",
       "      <td>저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>254</td>\n",
       "      <td>31</td>\n",
       "      <td>3.084112</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>117.615385</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>109.142857</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>512.333333</td>\n",
       "      <td>512.333333</td>\n",
       "      <td>769.000000</td>\n",
       "      <td>7.340187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>585982</td>\n",
       "      <td>4주일간 종교단체 집회를 강력하게 막아 코로나19 확산을 막아주세요</td>\n",
       "      <td>199.0</td>\n",
       "      <td>코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...</td>\n",
       "      <td>37</td>\n",
       "      <td>494</td>\n",
       "      <td>[코로나19, 촉발, 국민, 정신, 스트레스, 자영업자, 기업인, 경제, 손실, 가...</td>\n",
       "      <td>[있, 대하, 보, 보, 보이, 어기]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>[주일, 간, 종교, 단체, 집회, 코로나19, 확산]</td>\n",
       "      <td>[주일, 간, 종교, 단체, 집회, 코로나19, 확산, 코로나19, 촉발, 국민, ...</td>\n",
       "      <td>{'종교': 0.473, '단체': 0.399, '집회': 0.397, '주일': ...</td>\n",
       "      <td>10.049876</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...</td>\n",
       "      <td>코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>3.341880</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>6.202536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>908 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         code                                              title     count  \\\n",
       "9915   589340                용산 정비창 부지 8,000호 주택공급 계획에 대한 재검토 요청     494.0   \n",
       "11931  591390                                 양육비 대지급제 시행을 촉구합니다     362.0   \n",
       "8761   588168                               특수상권의 자영업자는 두번 죽습니다.     205.0   \n",
       "16730  596255      \"가야고분군\" 세계유산 등재신청에서 남원 유곡리와 두락리고분군은 제외하여 주십시요     128.0   \n",
       "4786   584120                  국가어항 슬롭웨이 만큼은 레져보트인이 사용할수 있게 해주세요     552.0   \n",
       "...       ...                                                ...       ...   \n",
       "104    593979  놀다 친구와 부딪힌 사고로 우리집의 6살 슈퍼히어로가 하늘나라로 출동했습니다. 어린...  206063.0   \n",
       "82     589634  '저의 딸이 강간 당하는 것을 목격하여..'  그 충격과 고통으로 딸이 평생 남을 ...  286148.0   \n",
       "3752   583065                   신기술의 거부감으로 인한 구시대의 규제를 완화하여 주십시요     218.0   \n",
       "14743  594239                                        농협비리를 고발합니다    1275.0   \n",
       "6616   585982              4주일간 종교단체 집회를 강력하게 막아 코로나19 확산을 막아주세요     199.0   \n",
       "\n",
       "                                               content_x     category  \\\n",
       "9915   최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...     교통/건축/국토   \n",
       "11931  저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....        육아/교육   \n",
       "8761   아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...         보건복지   \n",
       "16730  문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...  문화/예술/체육/언론   \n",
       "4786   우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...         농산어촌   \n",
       "...                                                  ...          ...   \n",
       "104    10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...        육아/교육   \n",
       "82     국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...       인권/성평등   \n",
       "3752   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...         성장동력   \n",
       "14743  저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...         농산어촌   \n",
       "6616   코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...         보건복지   \n",
       "\n",
       "      progress                                summary_content_end  title_len  \\\n",
       "9915     청원종료   최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...         35   \n",
       "11931    청원종료   저는 남편의 불륜으로 이혼 예정인 워킹맘입니다 사춘기 아이 둘을 둔 엄마이기도 합니...         18   \n",
       "8761     청원종료   아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다 매출이 반 토막보다 더...         20   \n",
       "16730    청원종료   문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...         45   \n",
       "4786     청원종료   우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며  그로 인해 레저보트 산업...         33   \n",
       "...        ...                                                ...        ...   \n",
       "104      답변완료   10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...         96   \n",
       "82       답변완료   국민청원 사유 저는 성폭행 당한 딸의 엄마입니다 그냥 피눈물이 주르륵 납니다  저의...         98   \n",
       "3752     청원종료   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...         32   \n",
       "14743    청원종료   저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...         11   \n",
       "6616     청원종료   코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...         37   \n",
       "\n",
       "       doc_len                                       content_noun  \\\n",
       "9915      2170  [최근, 용산정, 비창, 부지, 주택, 세대, 건립, 계획, 발표, 여론, 형성, ...   \n",
       "11931     1338  [남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아이, 엄마, 그간, 남편, 불륜,...   \n",
       "8761       291  [음식점, 업, 상공, 자영업자, 매출, 토막, 수준, 사정, 국민, 모두, 조금,...   \n",
       "16730     2278  [문재인, 대통령, 9월 10일, 문화재, 청, 문화재, 위원회, 세계유산, 분, ...   \n",
       "4786       653  [우리나라, 레져, 보트, 낚시, 인구, 급속, 증가, 추세, 레져, 보트, 산업,...   \n",
       "...        ...                                                ...   \n",
       "104       4083  [10월 21일, 수요일, 회사, 점심, 식사, 후, 커피, 아이, 어린이집, 전화...   \n",
       "82       10232  [국민, 사유, 성폭행, 딸, 엄마, 피눈물, 딸, 성폭행, 목격, 사건, 분, 본...   \n",
       "3752      3250  [국민, 요지, 특허청, 특허, 심사, 진행, 심사, 관, 특허, 명세서, 과학, ...   \n",
       "14743     1541  [해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, 농사, 재배, 농민, ...   \n",
       "6616       494  [코로나19, 촉발, 국민, 정신, 스트레스, 자영업자, 기업인, 경제, 손실, 가...   \n",
       "\n",
       "                                            content_verb  \\\n",
       "9915   [있, 보, 보, 앞서, 내세우, 되, 나아가, 통하, 돌아가, 엮이, 있, 갚, ...   \n",
       "11931  [두, 덮, 모르, 위하, 지키, 속이, 있, 걸, 헤어지, 끊, 돌아오, 보, 참...   \n",
       "8761           [있, 더하, 줄어들, 그러, 참, 버티, 버티, 되, 찾, 죽이, 처하]   \n",
       "16730  [지나, 지니, 되, 반하, 여기, 지나, 나타나, 보이, 두, 보, 맞, 이루, ...   \n",
       "4786   [인하, 되, 위하, 되, 있, 있, 즐기, 있, 있, 대하, 갖, 가, 대하, 쌓...   \n",
       "...                                                  ...   \n",
       "104    [마시, 있, 부딪히, 울, 되, 졸, 자, 일어나, 먹, 토하, 흘리, 가, 보,...   \n",
       "82     [당하, 나, 당하, 덮, 묻, 당하, 덮, 저지르, 저지르, 있, 위하, 넘어가,...   \n",
       "3752   [않, 되, 인하, 있, 인하, 대하, 있, 대하, 대하, 있, 달, 있, 대하, ...   \n",
       "14743  [있, 있, 있, 떠나, 가지, 있, 도와주, 드리, 묻, 따르, 막히, 들추, 지...   \n",
       "6616                               [있, 대하, 보, 보, 보이, 어기]   \n",
       "\n",
       "                                             content_adj      sdays  \\\n",
       "9915   [없, 같, 같, 뛰어나, 가깝, 없, 그렇, 많, 어떻, 아름답, 많, 없, 귀하... 2020-05-29   \n",
       "11931                       [그렇, 크, 없, 어떻, 없, 어렵, 없, 어떻] 2020-08-03   \n",
       "8761                               [힘들, 힘들, 같, 같, 작, 힘들] 2020-04-19   \n",
       "16730             [크, 많, 그렇, 다르, 없, 그렇, 넓, 좋, 멀, 안타깝, 없] 2021-02-05   \n",
       "4786                                           [시, 없, 시] 2019-12-20   \n",
       "...                                                  ...        ...   \n",
       "104    [크, 짧, 같, 적, 적, 없, 이렇, 어떻, 크, 많, 없, 괜찮, 같, 힘들,... 2020-11-13   \n",
       "82     [많, 없, 그렇, 못되, 못되, 없, 아프, 없, 어이없, 못되, 그렇, 뻔하, ... 2020-06-11   \n",
       "3752       [없, 안타깝, 어렵, 크, 없, 없, 많, 없, 없, 없, 없, 많, 없, 없] 2019-10-11   \n",
       "14743                       [어렵, 낮, 기막히, 없, 없, 싫, 없, 수많] 2020-11-27   \n",
       "6616                                                  [] 2020-03-02   \n",
       "\n",
       "           edays                                        title_token  \\\n",
       "9915  2020-06-28            [용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청]   \n",
       "11931 2020-09-02                                 [양육비, 대지급, 시행, 촉구]   \n",
       "8761  2020-05-19                                  [특수, 상권, 자영업자, 번]   \n",
       "16730 2021-03-07  [가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...   \n",
       "4786  2020-01-19                        [국가, 어항, 만큼, 레져, 보트, 인, 사용]   \n",
       "...          ...                                                ...   \n",
       "104   2020-12-13  [친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...   \n",
       "82    2020-07-11  [딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...   \n",
       "3752  2019-11-10                             [신기술, 거부감, 시대, 규제, 완화]   \n",
       "14743 2020-12-27                                       [농협, 비리, 고발]   \n",
       "6616  2020-04-01                     [주일, 간, 종교, 단체, 집회, 코로나19, 확산]   \n",
       "\n",
       "                                             total_token  \\\n",
       "9915   [용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청, 최근, 용산...   \n",
       "11931  [양육비, 대지급, 시행, 촉구, 남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아...   \n",
       "8761   [특수, 상권, 자영업자, 번, 음식점, 업, 상공, 자영업자, 매출, 토막, 수준...   \n",
       "16730  [가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...   \n",
       "4786   [국가, 어항, 만큼, 레져, 보트, 인, 사용, 우리나라, 레져, 보트, 낚시, ...   \n",
       "...                                                  ...   \n",
       "104    [친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...   \n",
       "82     [딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...   \n",
       "3752   [신기술, 거부감, 시대, 규제, 완화, 국민, 요지, 특허청, 특허, 심사, 진행...   \n",
       "14743  [농협, 비리, 고발, 해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, ...   \n",
       "6616   [주일, 간, 종교, 단체, 집회, 코로나19, 확산, 코로나19, 촉발, 국민, ...   \n",
       "\n",
       "                                             top_keyword  count_noun  \\\n",
       "9915   {'용산': 0.391, '국제': 0.31, '입지': 0.266, '부지': 0...   18.654758   \n",
       "11931  {'양육비': 0.52, '한부모': 0.441, '이혼': 0.213, '불륜':...   14.106736   \n",
       "8761   {'매장': 0.52, '상공': 0.384, '특수': 0.369, '자영업자':...    6.082763   \n",
       "16730  {'가야': 0.589, '남원': 0.327, '백제': 0.302, '등재': ...   20.663978   \n",
       "4786   {'레져': 0.6, '보트': 0.587, '낚시': 0.152, '어민': 0....   10.583005   \n",
       "...                                                  ...         ...   \n",
       "104    {'어린이집': 0.471, '교사': 0.341, '세바': 0.286, '보육'...   23.937418   \n",
       "82     {'증거': 0.285, '진술': 0.283, '가해자': 0.282, '성폭행'...   39.458839   \n",
       "3752   {'심사': 0.402, '특허': 0.397, '특허청': 0.354, '기술':...   23.853721   \n",
       "14743  {'농협': 0.453, '조합장': 0.449, '농민': 0.383, '운영':...   16.278821   \n",
       "6616   {'종교': 0.473, '단체': 0.399, '집회': 0.397, '주일': ...   10.049876   \n",
       "\n",
       "       count_verb  count_adj  target  \\\n",
       "9915     7.810250   4.242641       0   \n",
       "11931    7.810250   2.828427       0   \n",
       "8761     3.316625   2.449490       0   \n",
       "16730    6.082763   3.316625       0   \n",
       "4786     4.690416   1.732051       0   \n",
       "...           ...        ...     ...   \n",
       "104     12.961481   6.708204       1   \n",
       "82      16.643317   8.062258       1   \n",
       "3752     7.071068   3.741657       0   \n",
       "14743    7.071068   2.828427       0   \n",
       "6616     2.449490   0.000000       0   \n",
       "\n",
       "                                               content_y  \\\n",
       "9915   최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...   \n",
       "11931  저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....   \n",
       "8761   아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...   \n",
       "16730  문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...   \n",
       "4786   우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...   \n",
       "...                                                  ...   \n",
       "104    10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...   \n",
       "82     국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...   \n",
       "3752   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...   \n",
       "14743  저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...   \n",
       "6616   코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...   \n",
       "\n",
       "                                             pre_content  emotion_angry  \\\n",
       "9915   최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...              1   \n",
       "11931  저는 남편의 불륜으로 이혼 예정인 워킹맘입니다. 사춘기 아이 둘을 둔 엄마이기도 합...              0   \n",
       "8761   아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다. 매출이 반 토막보다 ...              0   \n",
       "16730  문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...              1   \n",
       "4786   우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며. 그로 인해 레저보트 산업...              1   \n",
       "...                                                  ...            ...   \n",
       "104    10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...              1   \n",
       "82     국민청원 사유 저는 성폭행 당한 딸의 엄마입니다. 그냥 피눈물이 주르륵 납니다. 저...              0   \n",
       "3752   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...              0   \n",
       "14743  저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...              1   \n",
       "6616   코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...              1   \n",
       "\n",
       "       emotion_disgust  emotion_dontknow  emotion_fear  emotion_sad  \\\n",
       "9915                 0                 0             0            0   \n",
       "11931                1                 0             0            0   \n",
       "8761                 0                 0             0            1   \n",
       "16730                0                 0             0            0   \n",
       "4786                 0                 0             0            0   \n",
       "...                ...               ...           ...          ...   \n",
       "104                  0                 0             0            0   \n",
       "82                   0                 0             0            1   \n",
       "3752                 0                 0             0            1   \n",
       "14743                0                 0             0            0   \n",
       "6616                 0                 0             0            0   \n",
       "\n",
       "       num_words  num_unique_words  num_punctuations  mean_word_len  \\\n",
       "9915         519               439                62       3.165703   \n",
       "11931        343               290                44       3.128280   \n",
       "8761          72                66                 5       3.138889   \n",
       "16730        519               417                55       3.281310   \n",
       "4786         153               131                21       3.084967   \n",
       "...          ...               ...               ...            ...   \n",
       "104         1053               762               152       2.898386   \n",
       "82          2417              1254               576       2.927596   \n",
       "3752         712               457               151       3.526685   \n",
       "14743        321               254                31       3.084112   \n",
       "6616         117               106                 4       3.341880   \n",
       "\n",
       "       title_mean_word_len            ,        ;             \"       ...  \\\n",
       "9915              3.000000    97.681818   2170.0   2170.000000  2170.000   \n",
       "11931             3.750000  1338.000000   1338.0   1338.000000   332.250   \n",
       "8761              4.250000   291.000000    291.0    291.000000   291.000   \n",
       "16730             4.750000   107.523810   2278.0    454.800000  2278.000   \n",
       "4786              3.857143   217.000000    653.0    653.000000   653.000   \n",
       "...                    ...          ...      ...           ...       ...   \n",
       "104               3.409091    51.358974   4083.0   4083.000000  4083.000   \n",
       "82                3.217391   111.450549  10232.0  10232.000000  1276.375   \n",
       "3752              3.714286    55.051724   3250.0    360.222222  3250.000   \n",
       "14743             5.000000   770.000000   1541.0   1541.000000  1541.000   \n",
       "6616              3.750000   246.500000    494.0    494.000000   494.000   \n",
       "\n",
       "              ?            !           .            :            *  \\\n",
       "9915    216.100  2170.000000   66.843750  2170.000000  2170.000000   \n",
       "11931   166.375  1338.000000   37.257143  1338.000000  1338.000000   \n",
       "8761    291.000   291.000000   47.666667   291.000000   291.000000   \n",
       "16730  2278.000  2278.000000  125.611111  2278.000000   568.750000   \n",
       "4786    653.000   653.000000   53.500000   653.000000    92.428571   \n",
       "...         ...          ...         ...          ...          ...   \n",
       "104    4083.000  4083.000000   76.056604  2041.000000  4083.000000   \n",
       "82      681.200   351.862069   80.214286   408.320000   261.384615   \n",
       "3752   3250.000  3250.000000   84.552632  1082.666667  3250.000000   \n",
       "14743  1541.000  1541.000000  117.615385   770.000000   109.142857   \n",
       "6616    494.000   494.000000  494.000000   494.000000   494.000000   \n",
       "\n",
       "                 -        ■            ★        @       please          chu  \\\n",
       "9915   1084.500000   2170.0  2170.000000   2170.0  2170.000000  2170.000000   \n",
       "11931  1338.000000   1338.0  1338.000000   1338.0   668.000000  1338.000000   \n",
       "8761    291.000000    291.0   291.000000    291.0   291.000000   291.000000   \n",
       "16730  2278.000000   2278.0  2278.000000   2278.0  2278.000000   568.000000   \n",
       "4786    653.000000    653.0   653.000000    653.0   325.500000   325.500000   \n",
       "...            ...      ...          ...      ...          ...          ...   \n",
       "104     679.666667   4083.0  4083.000000   4083.0  2040.500000  2040.500000   \n",
       "82      291.371429  10232.0   600.941176  10232.0  2044.800000  3409.333333   \n",
       "3752    170.105263   3250.0  3250.000000   3250.0  3250.000000   811.000000   \n",
       "14743  1541.000000   1541.0  1541.000000   1541.0   512.333333   512.333333   \n",
       "6616    494.000000    494.0   494.000000    494.0   494.000000   494.000000   \n",
       "\n",
       "              moon   log_doc  \n",
       "9915   2170.000000  7.682482  \n",
       "11931   444.000000  7.198931  \n",
       "8761    291.000000  5.673323  \n",
       "16730   453.200000  7.731053  \n",
       "4786    653.000000  6.481577  \n",
       "...            ...       ...  \n",
       "104    4083.000000  8.314587  \n",
       "82     1702.833333  9.233275  \n",
       "3752   3250.000000  8.086410  \n",
       "14743   769.000000  7.340187  \n",
       "6616    494.000000  6.202536  \n",
       "\n",
       "[908 rows x 50 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\",100)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "splot =  sns.countplot(train_df['target'])\n",
    "\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.0f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   size=15,\n",
    "                   xytext = (0, -12), \n",
    "                   textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 관계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='doc_len'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(train_df['target'],train_df['doc_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nfrom matplotlib import font_manager, rc\\nfont_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\\nrc(\\'font\\', family=font_name)\\nimport seaborn as sns\\n\\nfig, ax = plt.subplots(figsize = (12,8))\\n\\nsplot =  sns.countplot(sorted(train_df[\\'emotion\\']))\\nplt.title(\"글의 감정 분포\", fontsize = 12)\\nfor p in splot.patches:\\n    splot.annotate(format(p.get_height(), \\'.0f\\'), \\n                   (p.get_x() + p.get_width() / 2., p.get_height()), \\n                   ha = \\'center\\', va = \\'center\\', \\n                   size=15,\\n                   xytext = (0, -12), \\n                   textcoords = \\'offset points\\')\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "\n",
    "splot =  sns.countplot(sorted(train_df['emotion']))\n",
    "plt.title(\"글의 감정 분포\", fontsize = 12)\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.0f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   size=15,\n",
    "                   xytext = (0, -12), \n",
    "                   textcoords = 'offset points')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom matplotlib import font_manager, rc\\nfont_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\\nrc(\\'font\\', family=font_name)\\n\\n\\nfig, ax = plt.subplots(figsize = (12,8))\\n\\npd.crosstab(train_df[\\'target\\'], train_df[\\'emotion\\']).plot(kind = \\'bar\\', ax = ax)\\nax.legend(fontsize=12, loc=\\'upper left\\') # legend position\\nplt.title(\"target 별 글의 감정\", fontsize = 16)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "\n",
    "pd.crosstab(train_df['target'], train_df['emotion']).plot(kind = 'bar', ax = ax)\n",
    "ax.legend(fontsize=12, loc='upper left') # legend position\n",
    "plt.title(\"target 별 글의 감정\", fontsize = 16)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* target 별로 구분되는 특징이 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_lst = [' '.join(x) for x in train_df['total_token']]\n",
    "test_doc_lst = [' '.join(x) for x in test_df['total_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(908, 300) (228, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features = 300)\n",
    "\n",
    "full_tfidf = tfidf.fit_transform(train_doc_lst)\n",
    "train_tfidf = tfidf.transform(train_doc_lst)\n",
    "test_tfidf = tfidf.transform(test_doc_lst)\n",
    "print(train_tfidf.shape,test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_tfidf = []\n",
    "for i in range(len(test_doc_lst)):\n",
    "    total_test_tfidf.append(list(reversed(sorted(test_tfidf.toarray()[i])))[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "print(len(total_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_tfidf = []\n",
    "for i in range(len(train_doc_lst)):\n",
    "    total_train_tfidf.append(list(reversed(sorted(train_tfidf.toarray()[i])))[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n"
     ]
    }
   ],
   "source": [
    "print(len(total_train_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_df = pd.DataFrame(total_train_tfidf)\n",
    "test_tfidf_df = pd.DataFrame(total_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "      <th>content_x</th>\n",
       "      <th>category</th>\n",
       "      <th>progress</th>\n",
       "      <th>summary_content_end</th>\n",
       "      <th>title_len</th>\n",
       "      <th>doc_len</th>\n",
       "      <th>content_noun</th>\n",
       "      <th>content_verb</th>\n",
       "      <th>content_adj</th>\n",
       "      <th>sdays</th>\n",
       "      <th>edays</th>\n",
       "      <th>title_token</th>\n",
       "      <th>total_token</th>\n",
       "      <th>top_keyword</th>\n",
       "      <th>count_noun</th>\n",
       "      <th>count_verb</th>\n",
       "      <th>count_adj</th>\n",
       "      <th>target</th>\n",
       "      <th>content_y</th>\n",
       "      <th>pre_content</th>\n",
       "      <th>emotion_angry</th>\n",
       "      <th>emotion_disgust</th>\n",
       "      <th>emotion_dontknow</th>\n",
       "      <th>emotion_fear</th>\n",
       "      <th>emotion_sad</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>title_mean_word_len</th>\n",
       "      <th>,</th>\n",
       "      <th>;</th>\n",
       "      <th>\"</th>\n",
       "      <th>...</th>\n",
       "      <th>?</th>\n",
       "      <th>!</th>\n",
       "      <th>.</th>\n",
       "      <th>:</th>\n",
       "      <th>*</th>\n",
       "      <th>-</th>\n",
       "      <th>■</th>\n",
       "      <th>★</th>\n",
       "      <th>@</th>\n",
       "      <th>please</th>\n",
       "      <th>chu</th>\n",
       "      <th>moon</th>\n",
       "      <th>log_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>589340</td>\n",
       "      <td>용산 정비창 부지 8,000호 주택공급 계획에 대한 재검토 요청</td>\n",
       "      <td>494.0</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>35</td>\n",
       "      <td>2170</td>\n",
       "      <td>[최근, 용산정, 비창, 부지, 주택, 세대, 건립, 계획, 발표, 여론, 형성, ...</td>\n",
       "      <td>[있, 보, 보, 앞서, 내세우, 되, 나아가, 통하, 돌아가, 엮이, 있, 갚, ...</td>\n",
       "      <td>[없, 같, 같, 뛰어나, 가깝, 없, 그렇, 많, 어떻, 아름답, 많, 없, 귀하...</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>[용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청]</td>\n",
       "      <td>[용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청, 최근, 용산...</td>\n",
       "      <td>{'용산': 0.391, '국제': 0.31, '입지': 0.266, '부지': 0...</td>\n",
       "      <td>18.654758</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>0</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>439</td>\n",
       "      <td>62</td>\n",
       "      <td>3.165703</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>97.681818</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000</td>\n",
       "      <td>216.100</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>66.843750</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>1084.500000</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>7.682482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11931</th>\n",
       "      <td>591390</td>\n",
       "      <td>양육비 대지급제 시행을 촉구합니다</td>\n",
       "      <td>362.0</td>\n",
       "      <td>저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>저는 남편의 불륜으로 이혼 예정인 워킹맘입니다 사춘기 아이 둘을 둔 엄마이기도 합니...</td>\n",
       "      <td>18</td>\n",
       "      <td>1338</td>\n",
       "      <td>[남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아이, 엄마, 그간, 남편, 불륜,...</td>\n",
       "      <td>[두, 덮, 모르, 위하, 지키, 속이, 있, 걸, 헤어지, 끊, 돌아오, 보, 참...</td>\n",
       "      <td>[그렇, 크, 없, 어떻, 없, 어렵, 없, 어떻]</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>[양육비, 대지급, 시행, 촉구]</td>\n",
       "      <td>[양육비, 대지급, 시행, 촉구, 남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아...</td>\n",
       "      <td>{'양육비': 0.52, '한부모': 0.441, '이혼': 0.213, '불륜':...</td>\n",
       "      <td>14.106736</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0</td>\n",
       "      <td>저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....</td>\n",
       "      <td>저는 남편의 불륜으로 이혼 예정인 워킹맘입니다. 사춘기 아이 둘을 둔 엄마이기도 합...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>290</td>\n",
       "      <td>44</td>\n",
       "      <td>3.128280</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>332.250</td>\n",
       "      <td>166.375</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>37.257143</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>7.198931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>588168</td>\n",
       "      <td>특수상권의 자영업자는 두번 죽습니다.</td>\n",
       "      <td>205.0</td>\n",
       "      <td>아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다 매출이 반 토막보다 더...</td>\n",
       "      <td>20</td>\n",
       "      <td>291</td>\n",
       "      <td>[음식점, 업, 상공, 자영업자, 매출, 토막, 수준, 사정, 국민, 모두, 조금,...</td>\n",
       "      <td>[있, 더하, 줄어들, 그러, 참, 버티, 버티, 되, 찾, 죽이, 처하]</td>\n",
       "      <td>[힘들, 힘들, 같, 같, 작, 힘들]</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>[특수, 상권, 자영업자, 번]</td>\n",
       "      <td>[특수, 상권, 자영업자, 번, 음식점, 업, 상공, 자영업자, 매출, 토막, 수준...</td>\n",
       "      <td>{'매장': 0.52, '상공': 0.384, '특수': 0.369, '자영업자':...</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0</td>\n",
       "      <td>아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...</td>\n",
       "      <td>아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다. 매출이 반 토막보다 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>3.138889</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>5.673323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16730</th>\n",
       "      <td>596255</td>\n",
       "      <td>\"가야고분군\" 세계유산 등재신청에서 남원 유곡리와 두락리고분군은 제외하여 주십시요</td>\n",
       "      <td>128.0</td>\n",
       "      <td>문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...</td>\n",
       "      <td>문화/예술/체육/언론</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...</td>\n",
       "      <td>45</td>\n",
       "      <td>2278</td>\n",
       "      <td>[문재인, 대통령, 9월 10일, 문화재, 청, 문화재, 위원회, 세계유산, 분, ...</td>\n",
       "      <td>[지나, 지니, 되, 반하, 여기, 지나, 나타나, 보이, 두, 보, 맞, 이루, ...</td>\n",
       "      <td>[크, 많, 그렇, 다르, 없, 그렇, 넓, 좋, 멀, 안타깝, 없]</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>[가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...</td>\n",
       "      <td>[가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...</td>\n",
       "      <td>{'가야': 0.589, '남원': 0.327, '백제': 0.302, '등재': ...</td>\n",
       "      <td>20.663978</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0</td>\n",
       "      <td>문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...</td>\n",
       "      <td>문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>417</td>\n",
       "      <td>55</td>\n",
       "      <td>3.281310</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>107.523810</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>454.800000</td>\n",
       "      <td>2278.000</td>\n",
       "      <td>2278.000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>125.611111</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>568.750000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>453.200000</td>\n",
       "      <td>7.731053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>584120</td>\n",
       "      <td>국가어항 슬롭웨이 만큼은 레져보트인이 사용할수 있게 해주세요</td>\n",
       "      <td>552.0</td>\n",
       "      <td>우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...</td>\n",
       "      <td>농산어촌</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며  그로 인해 레저보트 산업...</td>\n",
       "      <td>33</td>\n",
       "      <td>653</td>\n",
       "      <td>[우리나라, 레져, 보트, 낚시, 인구, 급속, 증가, 추세, 레져, 보트, 산업,...</td>\n",
       "      <td>[인하, 되, 위하, 되, 있, 있, 즐기, 있, 있, 대하, 갖, 가, 대하, 쌓...</td>\n",
       "      <td>[시, 없, 시]</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>[국가, 어항, 만큼, 레져, 보트, 인, 사용]</td>\n",
       "      <td>[국가, 어항, 만큼, 레져, 보트, 인, 사용, 우리나라, 레져, 보트, 낚시, ...</td>\n",
       "      <td>{'레져': 0.6, '보트': 0.587, '낚시': 0.152, '어민': 0....</td>\n",
       "      <td>10.583005</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0</td>\n",
       "      <td>우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...</td>\n",
       "      <td>우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며. 그로 인해 레저보트 산업...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>131</td>\n",
       "      <td>21</td>\n",
       "      <td>3.084967</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000</td>\n",
       "      <td>653.000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>92.428571</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>325.500000</td>\n",
       "      <td>325.500000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>6.481577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>593979</td>\n",
       "      <td>놀다 친구와 부딪힌 사고로 우리집의 6살 슈퍼히어로가 하늘나라로 출동했습니다. 어린...</td>\n",
       "      <td>206063.0</td>\n",
       "      <td>10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>답변완료</td>\n",
       "      <td>10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>96</td>\n",
       "      <td>4083</td>\n",
       "      <td>[10월 21일, 수요일, 회사, 점심, 식사, 후, 커피, 아이, 어린이집, 전화...</td>\n",
       "      <td>[마시, 있, 부딪히, 울, 되, 졸, 자, 일어나, 먹, 토하, 흘리, 가, 보,...</td>\n",
       "      <td>[크, 짧, 같, 적, 적, 없, 이렇, 어떻, 크, 많, 없, 괜찮, 같, 힘들,...</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>2020-12-13</td>\n",
       "      <td>[친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...</td>\n",
       "      <td>[친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...</td>\n",
       "      <td>{'어린이집': 0.471, '교사': 0.341, '세바': 0.286, '보육'...</td>\n",
       "      <td>23.937418</td>\n",
       "      <td>12.961481</td>\n",
       "      <td>6.708204</td>\n",
       "      <td>1</td>\n",
       "      <td>10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "      <td>762</td>\n",
       "      <td>152</td>\n",
       "      <td>2.898386</td>\n",
       "      <td>3.409091</td>\n",
       "      <td>51.358974</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>4083.000</td>\n",
       "      <td>4083.000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>76.056604</td>\n",
       "      <td>2041.000000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>679.666667</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>2040.500000</td>\n",
       "      <td>2040.500000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>8.314587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>589634</td>\n",
       "      <td>'저의 딸이 강간 당하는 것을 목격하여..'  그 충격과 고통으로 딸이 평생 남을 ...</td>\n",
       "      <td>286148.0</td>\n",
       "      <td>국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...</td>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>답변완료</td>\n",
       "      <td>국민청원 사유 저는 성폭행 당한 딸의 엄마입니다 그냥 피눈물이 주르륵 납니다  저의...</td>\n",
       "      <td>98</td>\n",
       "      <td>10232</td>\n",
       "      <td>[국민, 사유, 성폭행, 딸, 엄마, 피눈물, 딸, 성폭행, 목격, 사건, 분, 본...</td>\n",
       "      <td>[당하, 나, 당하, 덮, 묻, 당하, 덮, 저지르, 저지르, 있, 위하, 넘어가,...</td>\n",
       "      <td>[많, 없, 그렇, 못되, 못되, 없, 아프, 없, 어이없, 못되, 그렇, 뻔하, ...</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>2020-07-11</td>\n",
       "      <td>[딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...</td>\n",
       "      <td>[딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...</td>\n",
       "      <td>{'증거': 0.285, '진술': 0.283, '가해자': 0.282, '성폭행'...</td>\n",
       "      <td>39.458839</td>\n",
       "      <td>16.643317</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>1</td>\n",
       "      <td>국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...</td>\n",
       "      <td>국민청원 사유 저는 성폭행 당한 딸의 엄마입니다. 그냥 피눈물이 주르륵 납니다. 저...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2417</td>\n",
       "      <td>1254</td>\n",
       "      <td>576</td>\n",
       "      <td>2.927596</td>\n",
       "      <td>3.217391</td>\n",
       "      <td>111.450549</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>10232.000000</td>\n",
       "      <td>1276.375</td>\n",
       "      <td>681.200</td>\n",
       "      <td>351.862069</td>\n",
       "      <td>80.214286</td>\n",
       "      <td>408.320000</td>\n",
       "      <td>261.384615</td>\n",
       "      <td>291.371429</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>600.941176</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>2044.800000</td>\n",
       "      <td>3409.333333</td>\n",
       "      <td>1702.833333</td>\n",
       "      <td>9.233275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>583065</td>\n",
       "      <td>신기술의 거부감으로 인한 구시대의 규제를 완화하여 주십시요</td>\n",
       "      <td>218.0</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...</td>\n",
       "      <td>성장동력</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...</td>\n",
       "      <td>32</td>\n",
       "      <td>3250</td>\n",
       "      <td>[국민, 요지, 특허청, 특허, 심사, 진행, 심사, 관, 특허, 명세서, 과학, ...</td>\n",
       "      <td>[않, 되, 인하, 있, 인하, 대하, 있, 대하, 대하, 있, 달, 있, 대하, ...</td>\n",
       "      <td>[없, 안타깝, 어렵, 크, 없, 없, 많, 없, 없, 없, 없, 많, 없, 없]</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>[신기술, 거부감, 시대, 규제, 완화]</td>\n",
       "      <td>[신기술, 거부감, 시대, 규제, 완화, 국민, 요지, 특허청, 특허, 심사, 진행...</td>\n",
       "      <td>{'심사': 0.402, '특허': 0.397, '특허청': 0.354, '기술':...</td>\n",
       "      <td>23.853721</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>457</td>\n",
       "      <td>151</td>\n",
       "      <td>3.526685</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>55.051724</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>360.222222</td>\n",
       "      <td>3250.000</td>\n",
       "      <td>3250.000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>84.552632</td>\n",
       "      <td>1082.666667</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>170.105263</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>8.086410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14743</th>\n",
       "      <td>594239</td>\n",
       "      <td>농협비리를 고발합니다</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...</td>\n",
       "      <td>농산어촌</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...</td>\n",
       "      <td>11</td>\n",
       "      <td>1541</td>\n",
       "      <td>[해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, 농사, 재배, 농민, ...</td>\n",
       "      <td>[있, 있, 있, 떠나, 가지, 있, 도와주, 드리, 묻, 따르, 막히, 들추, 지...</td>\n",
       "      <td>[어렵, 낮, 기막히, 없, 없, 싫, 없, 수많]</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>[농협, 비리, 고발]</td>\n",
       "      <td>[농협, 비리, 고발, 해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, ...</td>\n",
       "      <td>{'농협': 0.453, '조합장': 0.449, '농민': 0.383, '운영':...</td>\n",
       "      <td>16.278821</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0</td>\n",
       "      <td>저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...</td>\n",
       "      <td>저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>254</td>\n",
       "      <td>31</td>\n",
       "      <td>3.084112</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>117.615385</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>109.142857</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>512.333333</td>\n",
       "      <td>512.333333</td>\n",
       "      <td>769.000000</td>\n",
       "      <td>7.340187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>585982</td>\n",
       "      <td>4주일간 종교단체 집회를 강력하게 막아 코로나19 확산을 막아주세요</td>\n",
       "      <td>199.0</td>\n",
       "      <td>코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...</td>\n",
       "      <td>37</td>\n",
       "      <td>494</td>\n",
       "      <td>[코로나19, 촉발, 국민, 정신, 스트레스, 자영업자, 기업인, 경제, 손실, 가...</td>\n",
       "      <td>[있, 대하, 보, 보, 보이, 어기]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>[주일, 간, 종교, 단체, 집회, 코로나19, 확산]</td>\n",
       "      <td>[주일, 간, 종교, 단체, 집회, 코로나19, 확산, 코로나19, 촉발, 국민, ...</td>\n",
       "      <td>{'종교': 0.473, '단체': 0.399, '집회': 0.397, '주일': ...</td>\n",
       "      <td>10.049876</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...</td>\n",
       "      <td>코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>3.341880</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>6.202536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>908 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         code                                              title     count  \\\n",
       "9915   589340                용산 정비창 부지 8,000호 주택공급 계획에 대한 재검토 요청     494.0   \n",
       "11931  591390                                 양육비 대지급제 시행을 촉구합니다     362.0   \n",
       "8761   588168                               특수상권의 자영업자는 두번 죽습니다.     205.0   \n",
       "16730  596255      \"가야고분군\" 세계유산 등재신청에서 남원 유곡리와 두락리고분군은 제외하여 주십시요     128.0   \n",
       "4786   584120                  국가어항 슬롭웨이 만큼은 레져보트인이 사용할수 있게 해주세요     552.0   \n",
       "...       ...                                                ...       ...   \n",
       "104    593979  놀다 친구와 부딪힌 사고로 우리집의 6살 슈퍼히어로가 하늘나라로 출동했습니다. 어린...  206063.0   \n",
       "82     589634  '저의 딸이 강간 당하는 것을 목격하여..'  그 충격과 고통으로 딸이 평생 남을 ...  286148.0   \n",
       "3752   583065                   신기술의 거부감으로 인한 구시대의 규제를 완화하여 주십시요     218.0   \n",
       "14743  594239                                        농협비리를 고발합니다    1275.0   \n",
       "6616   585982              4주일간 종교단체 집회를 강력하게 막아 코로나19 확산을 막아주세요     199.0   \n",
       "\n",
       "                                               content_x     category  \\\n",
       "9915   최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...     교통/건축/국토   \n",
       "11931  저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....        육아/교육   \n",
       "8761   아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...         보건복지   \n",
       "16730  문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...  문화/예술/체육/언론   \n",
       "4786   우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...         농산어촌   \n",
       "...                                                  ...          ...   \n",
       "104    10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...        육아/교육   \n",
       "82     국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...       인권/성평등   \n",
       "3752   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...         성장동력   \n",
       "14743  저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...         농산어촌   \n",
       "6616   코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...         보건복지   \n",
       "\n",
       "      progress                                summary_content_end  title_len  \\\n",
       "9915     청원종료   최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...         35   \n",
       "11931    청원종료   저는 남편의 불륜으로 이혼 예정인 워킹맘입니다 사춘기 아이 둘을 둔 엄마이기도 합니...         18   \n",
       "8761     청원종료   아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다 매출이 반 토막보다 더...         20   \n",
       "16730    청원종료   문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...         45   \n",
       "4786     청원종료   우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며  그로 인해 레저보트 산업...         33   \n",
       "...        ...                                                ...        ...   \n",
       "104      답변완료   10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...         96   \n",
       "82       답변완료   국민청원 사유 저는 성폭행 당한 딸의 엄마입니다 그냥 피눈물이 주르륵 납니다  저의...         98   \n",
       "3752     청원종료   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...         32   \n",
       "14743    청원종료   저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...         11   \n",
       "6616     청원종료   코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...         37   \n",
       "\n",
       "       doc_len                                       content_noun  \\\n",
       "9915      2170  [최근, 용산정, 비창, 부지, 주택, 세대, 건립, 계획, 발표, 여론, 형성, ...   \n",
       "11931     1338  [남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아이, 엄마, 그간, 남편, 불륜,...   \n",
       "8761       291  [음식점, 업, 상공, 자영업자, 매출, 토막, 수준, 사정, 국민, 모두, 조금,...   \n",
       "16730     2278  [문재인, 대통령, 9월 10일, 문화재, 청, 문화재, 위원회, 세계유산, 분, ...   \n",
       "4786       653  [우리나라, 레져, 보트, 낚시, 인구, 급속, 증가, 추세, 레져, 보트, 산업,...   \n",
       "...        ...                                                ...   \n",
       "104       4083  [10월 21일, 수요일, 회사, 점심, 식사, 후, 커피, 아이, 어린이집, 전화...   \n",
       "82       10232  [국민, 사유, 성폭행, 딸, 엄마, 피눈물, 딸, 성폭행, 목격, 사건, 분, 본...   \n",
       "3752      3250  [국민, 요지, 특허청, 특허, 심사, 진행, 심사, 관, 특허, 명세서, 과학, ...   \n",
       "14743     1541  [해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, 농사, 재배, 농민, ...   \n",
       "6616       494  [코로나19, 촉발, 국민, 정신, 스트레스, 자영업자, 기업인, 경제, 손실, 가...   \n",
       "\n",
       "                                            content_verb  \\\n",
       "9915   [있, 보, 보, 앞서, 내세우, 되, 나아가, 통하, 돌아가, 엮이, 있, 갚, ...   \n",
       "11931  [두, 덮, 모르, 위하, 지키, 속이, 있, 걸, 헤어지, 끊, 돌아오, 보, 참...   \n",
       "8761           [있, 더하, 줄어들, 그러, 참, 버티, 버티, 되, 찾, 죽이, 처하]   \n",
       "16730  [지나, 지니, 되, 반하, 여기, 지나, 나타나, 보이, 두, 보, 맞, 이루, ...   \n",
       "4786   [인하, 되, 위하, 되, 있, 있, 즐기, 있, 있, 대하, 갖, 가, 대하, 쌓...   \n",
       "...                                                  ...   \n",
       "104    [마시, 있, 부딪히, 울, 되, 졸, 자, 일어나, 먹, 토하, 흘리, 가, 보,...   \n",
       "82     [당하, 나, 당하, 덮, 묻, 당하, 덮, 저지르, 저지르, 있, 위하, 넘어가,...   \n",
       "3752   [않, 되, 인하, 있, 인하, 대하, 있, 대하, 대하, 있, 달, 있, 대하, ...   \n",
       "14743  [있, 있, 있, 떠나, 가지, 있, 도와주, 드리, 묻, 따르, 막히, 들추, 지...   \n",
       "6616                               [있, 대하, 보, 보, 보이, 어기]   \n",
       "\n",
       "                                             content_adj      sdays  \\\n",
       "9915   [없, 같, 같, 뛰어나, 가깝, 없, 그렇, 많, 어떻, 아름답, 많, 없, 귀하... 2020-05-29   \n",
       "11931                       [그렇, 크, 없, 어떻, 없, 어렵, 없, 어떻] 2020-08-03   \n",
       "8761                               [힘들, 힘들, 같, 같, 작, 힘들] 2020-04-19   \n",
       "16730             [크, 많, 그렇, 다르, 없, 그렇, 넓, 좋, 멀, 안타깝, 없] 2021-02-05   \n",
       "4786                                           [시, 없, 시] 2019-12-20   \n",
       "...                                                  ...        ...   \n",
       "104    [크, 짧, 같, 적, 적, 없, 이렇, 어떻, 크, 많, 없, 괜찮, 같, 힘들,... 2020-11-13   \n",
       "82     [많, 없, 그렇, 못되, 못되, 없, 아프, 없, 어이없, 못되, 그렇, 뻔하, ... 2020-06-11   \n",
       "3752       [없, 안타깝, 어렵, 크, 없, 없, 많, 없, 없, 없, 없, 많, 없, 없] 2019-10-11   \n",
       "14743                       [어렵, 낮, 기막히, 없, 없, 싫, 없, 수많] 2020-11-27   \n",
       "6616                                                  [] 2020-03-02   \n",
       "\n",
       "           edays                                        title_token  \\\n",
       "9915  2020-06-28            [용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청]   \n",
       "11931 2020-09-02                                 [양육비, 대지급, 시행, 촉구]   \n",
       "8761  2020-05-19                                  [특수, 상권, 자영업자, 번]   \n",
       "16730 2021-03-07  [가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...   \n",
       "4786  2020-01-19                        [국가, 어항, 만큼, 레져, 보트, 인, 사용]   \n",
       "...          ...                                                ...   \n",
       "104   2020-12-13  [친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...   \n",
       "82    2020-07-11  [딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...   \n",
       "3752  2019-11-10                             [신기술, 거부감, 시대, 규제, 완화]   \n",
       "14743 2020-12-27                                       [농협, 비리, 고발]   \n",
       "6616  2020-04-01                     [주일, 간, 종교, 단체, 집회, 코로나19, 확산]   \n",
       "\n",
       "                                             total_token  \\\n",
       "9915   [용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청, 최근, 용산...   \n",
       "11931  [양육비, 대지급, 시행, 촉구, 남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아...   \n",
       "8761   [특수, 상권, 자영업자, 번, 음식점, 업, 상공, 자영업자, 매출, 토막, 수준...   \n",
       "16730  [가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...   \n",
       "4786   [국가, 어항, 만큼, 레져, 보트, 인, 사용, 우리나라, 레져, 보트, 낚시, ...   \n",
       "...                                                  ...   \n",
       "104    [친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...   \n",
       "82     [딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...   \n",
       "3752   [신기술, 거부감, 시대, 규제, 완화, 국민, 요지, 특허청, 특허, 심사, 진행...   \n",
       "14743  [농협, 비리, 고발, 해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, ...   \n",
       "6616   [주일, 간, 종교, 단체, 집회, 코로나19, 확산, 코로나19, 촉발, 국민, ...   \n",
       "\n",
       "                                             top_keyword  count_noun  \\\n",
       "9915   {'용산': 0.391, '국제': 0.31, '입지': 0.266, '부지': 0...   18.654758   \n",
       "11931  {'양육비': 0.52, '한부모': 0.441, '이혼': 0.213, '불륜':...   14.106736   \n",
       "8761   {'매장': 0.52, '상공': 0.384, '특수': 0.369, '자영업자':...    6.082763   \n",
       "16730  {'가야': 0.589, '남원': 0.327, '백제': 0.302, '등재': ...   20.663978   \n",
       "4786   {'레져': 0.6, '보트': 0.587, '낚시': 0.152, '어민': 0....   10.583005   \n",
       "...                                                  ...         ...   \n",
       "104    {'어린이집': 0.471, '교사': 0.341, '세바': 0.286, '보육'...   23.937418   \n",
       "82     {'증거': 0.285, '진술': 0.283, '가해자': 0.282, '성폭행'...   39.458839   \n",
       "3752   {'심사': 0.402, '특허': 0.397, '특허청': 0.354, '기술':...   23.853721   \n",
       "14743  {'농협': 0.453, '조합장': 0.449, '농민': 0.383, '운영':...   16.278821   \n",
       "6616   {'종교': 0.473, '단체': 0.399, '집회': 0.397, '주일': ...   10.049876   \n",
       "\n",
       "       count_verb  count_adj  target  \\\n",
       "9915     7.810250   4.242641       0   \n",
       "11931    7.810250   2.828427       0   \n",
       "8761     3.316625   2.449490       0   \n",
       "16730    6.082763   3.316625       0   \n",
       "4786     4.690416   1.732051       0   \n",
       "...           ...        ...     ...   \n",
       "104     12.961481   6.708204       1   \n",
       "82      16.643317   8.062258       1   \n",
       "3752     7.071068   3.741657       0   \n",
       "14743    7.071068   2.828427       0   \n",
       "6616     2.449490   0.000000       0   \n",
       "\n",
       "                                               content_y  \\\n",
       "9915   최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...   \n",
       "11931  저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....   \n",
       "8761   아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...   \n",
       "16730  문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...   \n",
       "4786   우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...   \n",
       "...                                                  ...   \n",
       "104    10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...   \n",
       "82     국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...   \n",
       "3752   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...   \n",
       "14743  저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...   \n",
       "6616   코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...   \n",
       "\n",
       "                                             pre_content  emotion_angry  \\\n",
       "9915   최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...              1   \n",
       "11931  저는 남편의 불륜으로 이혼 예정인 워킹맘입니다. 사춘기 아이 둘을 둔 엄마이기도 합...              0   \n",
       "8761   아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다. 매출이 반 토막보다 ...              0   \n",
       "16730  문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...              1   \n",
       "4786   우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며. 그로 인해 레저보트 산업...              1   \n",
       "...                                                  ...            ...   \n",
       "104    10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...              1   \n",
       "82     국민청원 사유 저는 성폭행 당한 딸의 엄마입니다. 그냥 피눈물이 주르륵 납니다. 저...              0   \n",
       "3752   국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...              0   \n",
       "14743  저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...              1   \n",
       "6616   코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...              1   \n",
       "\n",
       "       emotion_disgust  emotion_dontknow  emotion_fear  emotion_sad  \\\n",
       "9915                 0                 0             0            0   \n",
       "11931                1                 0             0            0   \n",
       "8761                 0                 0             0            1   \n",
       "16730                0                 0             0            0   \n",
       "4786                 0                 0             0            0   \n",
       "...                ...               ...           ...          ...   \n",
       "104                  0                 0             0            0   \n",
       "82                   0                 0             0            1   \n",
       "3752                 0                 0             0            1   \n",
       "14743                0                 0             0            0   \n",
       "6616                 0                 0             0            0   \n",
       "\n",
       "       num_words  num_unique_words  num_punctuations  mean_word_len  \\\n",
       "9915         519               439                62       3.165703   \n",
       "11931        343               290                44       3.128280   \n",
       "8761          72                66                 5       3.138889   \n",
       "16730        519               417                55       3.281310   \n",
       "4786         153               131                21       3.084967   \n",
       "...          ...               ...               ...            ...   \n",
       "104         1053               762               152       2.898386   \n",
       "82          2417              1254               576       2.927596   \n",
       "3752         712               457               151       3.526685   \n",
       "14743        321               254                31       3.084112   \n",
       "6616         117               106                 4       3.341880   \n",
       "\n",
       "       title_mean_word_len            ,        ;             \"       ...  \\\n",
       "9915              3.000000    97.681818   2170.0   2170.000000  2170.000   \n",
       "11931             3.750000  1338.000000   1338.0   1338.000000   332.250   \n",
       "8761              4.250000   291.000000    291.0    291.000000   291.000   \n",
       "16730             4.750000   107.523810   2278.0    454.800000  2278.000   \n",
       "4786              3.857143   217.000000    653.0    653.000000   653.000   \n",
       "...                    ...          ...      ...           ...       ...   \n",
       "104               3.409091    51.358974   4083.0   4083.000000  4083.000   \n",
       "82                3.217391   111.450549  10232.0  10232.000000  1276.375   \n",
       "3752              3.714286    55.051724   3250.0    360.222222  3250.000   \n",
       "14743             5.000000   770.000000   1541.0   1541.000000  1541.000   \n",
       "6616              3.750000   246.500000    494.0    494.000000   494.000   \n",
       "\n",
       "              ?            !           .            :            *  \\\n",
       "9915    216.100  2170.000000   66.843750  2170.000000  2170.000000   \n",
       "11931   166.375  1338.000000   37.257143  1338.000000  1338.000000   \n",
       "8761    291.000   291.000000   47.666667   291.000000   291.000000   \n",
       "16730  2278.000  2278.000000  125.611111  2278.000000   568.750000   \n",
       "4786    653.000   653.000000   53.500000   653.000000    92.428571   \n",
       "...         ...          ...         ...          ...          ...   \n",
       "104    4083.000  4083.000000   76.056604  2041.000000  4083.000000   \n",
       "82      681.200   351.862069   80.214286   408.320000   261.384615   \n",
       "3752   3250.000  3250.000000   84.552632  1082.666667  3250.000000   \n",
       "14743  1541.000  1541.000000  117.615385   770.000000   109.142857   \n",
       "6616    494.000   494.000000  494.000000   494.000000   494.000000   \n",
       "\n",
       "                 -        ■            ★        @       please          chu  \\\n",
       "9915   1084.500000   2170.0  2170.000000   2170.0  2170.000000  2170.000000   \n",
       "11931  1338.000000   1338.0  1338.000000   1338.0   668.000000  1338.000000   \n",
       "8761    291.000000    291.0   291.000000    291.0   291.000000   291.000000   \n",
       "16730  2278.000000   2278.0  2278.000000   2278.0  2278.000000   568.000000   \n",
       "4786    653.000000    653.0   653.000000    653.0   325.500000   325.500000   \n",
       "...            ...      ...          ...      ...          ...          ...   \n",
       "104     679.666667   4083.0  4083.000000   4083.0  2040.500000  2040.500000   \n",
       "82      291.371429  10232.0   600.941176  10232.0  2044.800000  3409.333333   \n",
       "3752    170.105263   3250.0  3250.000000   3250.0  3250.000000   811.000000   \n",
       "14743  1541.000000   1541.0  1541.000000   1541.0   512.333333   512.333333   \n",
       "6616    494.000000    494.0   494.000000    494.0   494.000000   494.000000   \n",
       "\n",
       "              moon   log_doc  \n",
       "9915   2170.000000  7.682482  \n",
       "11931   444.000000  7.198931  \n",
       "8761    291.000000  5.673323  \n",
       "16730   453.200000  7.731053  \n",
       "4786    653.000000  6.481577  \n",
       "...            ...       ...  \n",
       "104    4083.000000  8.314587  \n",
       "82     1702.833333  9.233275  \n",
       "3752   3250.000000  8.086410  \n",
       "14743   769.000000  7.340187  \n",
       "6616    494.000000  6.202536  \n",
       "\n",
       "[908 rows x 50 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "      <th>content_x</th>\n",
       "      <th>category</th>\n",
       "      <th>progress</th>\n",
       "      <th>summary_content_end</th>\n",
       "      <th>title_len</th>\n",
       "      <th>doc_len</th>\n",
       "      <th>content_noun</th>\n",
       "      <th>content_verb</th>\n",
       "      <th>content_adj</th>\n",
       "      <th>sdays</th>\n",
       "      <th>edays</th>\n",
       "      <th>title_token</th>\n",
       "      <th>total_token</th>\n",
       "      <th>top_keyword</th>\n",
       "      <th>count_noun</th>\n",
       "      <th>count_verb</th>\n",
       "      <th>count_adj</th>\n",
       "      <th>target</th>\n",
       "      <th>content_y</th>\n",
       "      <th>pre_content</th>\n",
       "      <th>emotion_angry</th>\n",
       "      <th>emotion_disgust</th>\n",
       "      <th>emotion_dontknow</th>\n",
       "      <th>emotion_fear</th>\n",
       "      <th>emotion_sad</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>title_mean_word_len</th>\n",
       "      <th>,</th>\n",
       "      <th>;</th>\n",
       "      <th>\"</th>\n",
       "      <th>...</th>\n",
       "      <th>?</th>\n",
       "      <th>!</th>\n",
       "      <th>.</th>\n",
       "      <th>:</th>\n",
       "      <th>*</th>\n",
       "      <th>-</th>\n",
       "      <th>■</th>\n",
       "      <th>★</th>\n",
       "      <th>@</th>\n",
       "      <th>please</th>\n",
       "      <th>chu</th>\n",
       "      <th>moon</th>\n",
       "      <th>log_doc</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589340</td>\n",
       "      <td>용산 정비창 부지 8,000호 주택공급 계획에 대한 재검토 요청</td>\n",
       "      <td>494.0</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>35</td>\n",
       "      <td>2170</td>\n",
       "      <td>[최근, 용산정, 비창, 부지, 주택, 세대, 건립, 계획, 발표, 여론, 형성, ...</td>\n",
       "      <td>[있, 보, 보, 앞서, 내세우, 되, 나아가, 통하, 돌아가, 엮이, 있, 갚, ...</td>\n",
       "      <td>[없, 같, 같, 뛰어나, 가깝, 없, 그렇, 많, 어떻, 아름답, 많, 없, 귀하...</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>[용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청]</td>\n",
       "      <td>[용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청, 최근, 용산...</td>\n",
       "      <td>{'용산': 0.391, '국제': 0.31, '입지': 0.266, '부지': 0...</td>\n",
       "      <td>18.654758</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>0</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>439</td>\n",
       "      <td>62</td>\n",
       "      <td>3.165703</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>97.681818</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000</td>\n",
       "      <td>216.100</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>66.843750</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>1084.500000</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>7.682482</td>\n",
       "      <td>0.424290</td>\n",
       "      <td>0.400065</td>\n",
       "      <td>0.371941</td>\n",
       "      <td>0.337048</td>\n",
       "      <td>0.313815</td>\n",
       "      <td>0.256219</td>\n",
       "      <td>0.216296</td>\n",
       "      <td>0.133494</td>\n",
       "      <td>0.126287</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>0.118307</td>\n",
       "      <td>0.117249</td>\n",
       "      <td>0.102693</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>0.076537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>591390</td>\n",
       "      <td>양육비 대지급제 시행을 촉구합니다</td>\n",
       "      <td>362.0</td>\n",
       "      <td>저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>저는 남편의 불륜으로 이혼 예정인 워킹맘입니다 사춘기 아이 둘을 둔 엄마이기도 합니...</td>\n",
       "      <td>18</td>\n",
       "      <td>1338</td>\n",
       "      <td>[남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아이, 엄마, 그간, 남편, 불륜,...</td>\n",
       "      <td>[두, 덮, 모르, 위하, 지키, 속이, 있, 걸, 헤어지, 끊, 돌아오, 보, 참...</td>\n",
       "      <td>[그렇, 크, 없, 어떻, 없, 어렵, 없, 어떻]</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>[양육비, 대지급, 시행, 촉구]</td>\n",
       "      <td>[양육비, 대지급, 시행, 촉구, 남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아...</td>\n",
       "      <td>{'양육비': 0.52, '한부모': 0.441, '이혼': 0.213, '불륜':...</td>\n",
       "      <td>14.106736</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0</td>\n",
       "      <td>저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....</td>\n",
       "      <td>저는 남편의 불륜으로 이혼 예정인 워킹맘입니다. 사춘기 아이 둘을 둔 엄마이기도 합...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>290</td>\n",
       "      <td>44</td>\n",
       "      <td>3.128280</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>332.250</td>\n",
       "      <td>166.375</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>37.257143</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>7.198931</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.395796</td>\n",
       "      <td>0.358760</td>\n",
       "      <td>0.231779</td>\n",
       "      <td>0.229750</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.168115</td>\n",
       "      <td>0.155442</td>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.147303</td>\n",
       "      <td>0.144989</td>\n",
       "      <td>0.129855</td>\n",
       "      <td>0.123611</td>\n",
       "      <td>0.108876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>588168</td>\n",
       "      <td>특수상권의 자영업자는 두번 죽습니다.</td>\n",
       "      <td>205.0</td>\n",
       "      <td>아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다 매출이 반 토막보다 더...</td>\n",
       "      <td>20</td>\n",
       "      <td>291</td>\n",
       "      <td>[음식점, 업, 상공, 자영업자, 매출, 토막, 수준, 사정, 국민, 모두, 조금,...</td>\n",
       "      <td>[있, 더하, 줄어들, 그러, 참, 버티, 버티, 되, 찾, 죽이, 처하]</td>\n",
       "      <td>[힘들, 힘들, 같, 같, 작, 힘들]</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>[특수, 상권, 자영업자, 번]</td>\n",
       "      <td>[특수, 상권, 자영업자, 번, 음식점, 업, 상공, 자영업자, 매출, 토막, 수준...</td>\n",
       "      <td>{'매장': 0.52, '상공': 0.384, '특수': 0.369, '자영업자':...</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0</td>\n",
       "      <td>아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...</td>\n",
       "      <td>아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다. 매출이 반 토막보다 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>3.138889</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>5.673323</td>\n",
       "      <td>0.731018</td>\n",
       "      <td>0.524812</td>\n",
       "      <td>0.301879</td>\n",
       "      <td>0.221965</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>0.131738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>596255</td>\n",
       "      <td>\"가야고분군\" 세계유산 등재신청에서 남원 유곡리와 두락리고분군은 제외하여 주십시요</td>\n",
       "      <td>128.0</td>\n",
       "      <td>문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...</td>\n",
       "      <td>문화/예술/체육/언론</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...</td>\n",
       "      <td>45</td>\n",
       "      <td>2278</td>\n",
       "      <td>[문재인, 대통령, 9월 10일, 문화재, 청, 문화재, 위원회, 세계유산, 분, ...</td>\n",
       "      <td>[지나, 지니, 되, 반하, 여기, 지나, 나타나, 보이, 두, 보, 맞, 이루, ...</td>\n",
       "      <td>[크, 많, 그렇, 다르, 없, 그렇, 넓, 좋, 멀, 안타깝, 없]</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>[가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...</td>\n",
       "      <td>[가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...</td>\n",
       "      <td>{'가야': 0.589, '남원': 0.327, '백제': 0.302, '등재': ...</td>\n",
       "      <td>20.663978</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0</td>\n",
       "      <td>문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...</td>\n",
       "      <td>문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>417</td>\n",
       "      <td>55</td>\n",
       "      <td>3.281310</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>107.523810</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>454.800000</td>\n",
       "      <td>2278.000</td>\n",
       "      <td>2278.000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>125.611111</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>568.750000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>453.200000</td>\n",
       "      <td>7.731053</td>\n",
       "      <td>0.618037</td>\n",
       "      <td>0.419106</td>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.209501</td>\n",
       "      <td>0.202697</td>\n",
       "      <td>0.188087</td>\n",
       "      <td>0.170882</td>\n",
       "      <td>0.169267</td>\n",
       "      <td>0.150096</td>\n",
       "      <td>0.138120</td>\n",
       "      <td>0.118363</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.078059</td>\n",
       "      <td>0.076876</td>\n",
       "      <td>0.076124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>584120</td>\n",
       "      <td>국가어항 슬롭웨이 만큼은 레져보트인이 사용할수 있게 해주세요</td>\n",
       "      <td>552.0</td>\n",
       "      <td>우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...</td>\n",
       "      <td>농산어촌</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며  그로 인해 레저보트 산업...</td>\n",
       "      <td>33</td>\n",
       "      <td>653</td>\n",
       "      <td>[우리나라, 레져, 보트, 낚시, 인구, 급속, 증가, 추세, 레져, 보트, 산업,...</td>\n",
       "      <td>[인하, 되, 위하, 되, 있, 있, 즐기, 있, 있, 대하, 갖, 가, 대하, 쌓...</td>\n",
       "      <td>[시, 없, 시]</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>[국가, 어항, 만큼, 레져, 보트, 인, 사용]</td>\n",
       "      <td>[국가, 어항, 만큼, 레져, 보트, 인, 사용, 우리나라, 레져, 보트, 낚시, ...</td>\n",
       "      <td>{'레져': 0.6, '보트': 0.587, '낚시': 0.152, '어민': 0....</td>\n",
       "      <td>10.583005</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0</td>\n",
       "      <td>우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...</td>\n",
       "      <td>우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며. 그로 인해 레저보트 산업...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>131</td>\n",
       "      <td>21</td>\n",
       "      <td>3.084967</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000</td>\n",
       "      <td>653.000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>92.428571</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.0</td>\n",
       "      <td>325.500000</td>\n",
       "      <td>325.500000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>6.481577</td>\n",
       "      <td>0.521381</td>\n",
       "      <td>0.518109</td>\n",
       "      <td>0.275852</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.210827</td>\n",
       "      <td>0.157344</td>\n",
       "      <td>0.140396</td>\n",
       "      <td>0.130866</td>\n",
       "      <td>0.129832</td>\n",
       "      <td>0.124611</td>\n",
       "      <td>0.124171</td>\n",
       "      <td>0.123307</td>\n",
       "      <td>0.115629</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.109148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>593979</td>\n",
       "      <td>놀다 친구와 부딪힌 사고로 우리집의 6살 슈퍼히어로가 하늘나라로 출동했습니다. 어린...</td>\n",
       "      <td>206063.0</td>\n",
       "      <td>10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>답변완료</td>\n",
       "      <td>10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>96</td>\n",
       "      <td>4083</td>\n",
       "      <td>[10월 21일, 수요일, 회사, 점심, 식사, 후, 커피, 아이, 어린이집, 전화...</td>\n",
       "      <td>[마시, 있, 부딪히, 울, 되, 졸, 자, 일어나, 먹, 토하, 흘리, 가, 보,...</td>\n",
       "      <td>[크, 짧, 같, 적, 적, 없, 이렇, 어떻, 크, 많, 없, 괜찮, 같, 힘들,...</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>2020-12-13</td>\n",
       "      <td>[친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...</td>\n",
       "      <td>[친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...</td>\n",
       "      <td>{'어린이집': 0.471, '교사': 0.341, '세바': 0.286, '보육'...</td>\n",
       "      <td>23.937418</td>\n",
       "      <td>12.961481</td>\n",
       "      <td>6.708204</td>\n",
       "      <td>1</td>\n",
       "      <td>10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "      <td>762</td>\n",
       "      <td>152</td>\n",
       "      <td>2.898386</td>\n",
       "      <td>3.409091</td>\n",
       "      <td>51.358974</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>4083.000</td>\n",
       "      <td>4083.000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>76.056604</td>\n",
       "      <td>2041.000000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>679.666667</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>2040.500000</td>\n",
       "      <td>2040.500000</td>\n",
       "      <td>4083.000000</td>\n",
       "      <td>8.314587</td>\n",
       "      <td>0.663262</td>\n",
       "      <td>0.489153</td>\n",
       "      <td>0.314064</td>\n",
       "      <td>0.264960</td>\n",
       "      <td>0.159139</td>\n",
       "      <td>0.144487</td>\n",
       "      <td>0.125898</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.088170</td>\n",
       "      <td>0.072542</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.062324</td>\n",
       "      <td>0.057353</td>\n",
       "      <td>0.052409</td>\n",
       "      <td>0.049074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>589634</td>\n",
       "      <td>'저의 딸이 강간 당하는 것을 목격하여..'  그 충격과 고통으로 딸이 평생 남을 ...</td>\n",
       "      <td>286148.0</td>\n",
       "      <td>국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...</td>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>답변완료</td>\n",
       "      <td>국민청원 사유 저는 성폭행 당한 딸의 엄마입니다 그냥 피눈물이 주르륵 납니다  저의...</td>\n",
       "      <td>98</td>\n",
       "      <td>10232</td>\n",
       "      <td>[국민, 사유, 성폭행, 딸, 엄마, 피눈물, 딸, 성폭행, 목격, 사건, 분, 본...</td>\n",
       "      <td>[당하, 나, 당하, 덮, 묻, 당하, 덮, 저지르, 저지르, 있, 위하, 넘어가,...</td>\n",
       "      <td>[많, 없, 그렇, 못되, 못되, 없, 아프, 없, 어이없, 못되, 그렇, 뻔하, ...</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>2020-07-11</td>\n",
       "      <td>[딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...</td>\n",
       "      <td>[딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...</td>\n",
       "      <td>{'증거': 0.285, '진술': 0.283, '가해자': 0.282, '성폭행'...</td>\n",
       "      <td>39.458839</td>\n",
       "      <td>16.643317</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>1</td>\n",
       "      <td>국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...</td>\n",
       "      <td>국민청원 사유 저는 성폭행 당한 딸의 엄마입니다. 그냥 피눈물이 주르륵 납니다. 저...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2417</td>\n",
       "      <td>1254</td>\n",
       "      <td>576</td>\n",
       "      <td>2.927596</td>\n",
       "      <td>3.217391</td>\n",
       "      <td>111.450549</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>10232.000000</td>\n",
       "      <td>1276.375</td>\n",
       "      <td>681.200</td>\n",
       "      <td>351.862069</td>\n",
       "      <td>80.214286</td>\n",
       "      <td>408.320000</td>\n",
       "      <td>261.384615</td>\n",
       "      <td>291.371429</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>600.941176</td>\n",
       "      <td>10232.0</td>\n",
       "      <td>2044.800000</td>\n",
       "      <td>3409.333333</td>\n",
       "      <td>1702.833333</td>\n",
       "      <td>9.233275</td>\n",
       "      <td>0.410463</td>\n",
       "      <td>0.376792</td>\n",
       "      <td>0.358840</td>\n",
       "      <td>0.316025</td>\n",
       "      <td>0.299607</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.261490</td>\n",
       "      <td>0.245893</td>\n",
       "      <td>0.182428</td>\n",
       "      <td>0.152785</td>\n",
       "      <td>0.115450</td>\n",
       "      <td>0.093620</td>\n",
       "      <td>0.090161</td>\n",
       "      <td>0.080589</td>\n",
       "      <td>0.077447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>583065</td>\n",
       "      <td>신기술의 거부감으로 인한 구시대의 규제를 완화하여 주십시요</td>\n",
       "      <td>218.0</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...</td>\n",
       "      <td>성장동력</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...</td>\n",
       "      <td>32</td>\n",
       "      <td>3250</td>\n",
       "      <td>[국민, 요지, 특허청, 특허, 심사, 진행, 심사, 관, 특허, 명세서, 과학, ...</td>\n",
       "      <td>[않, 되, 인하, 있, 인하, 대하, 있, 대하, 대하, 있, 달, 있, 대하, ...</td>\n",
       "      <td>[없, 안타깝, 어렵, 크, 없, 없, 많, 없, 없, 없, 없, 많, 없, 없]</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>[신기술, 거부감, 시대, 규제, 완화]</td>\n",
       "      <td>[신기술, 거부감, 시대, 규제, 완화, 국민, 요지, 특허청, 특허, 심사, 진행...</td>\n",
       "      <td>{'심사': 0.402, '특허': 0.397, '특허청': 0.354, '기술':...</td>\n",
       "      <td>23.853721</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...</td>\n",
       "      <td>국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>457</td>\n",
       "      <td>151</td>\n",
       "      <td>3.526685</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>55.051724</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>360.222222</td>\n",
       "      <td>3250.000</td>\n",
       "      <td>3250.000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>84.552632</td>\n",
       "      <td>1082.666667</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>170.105263</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>8.086410</td>\n",
       "      <td>0.519996</td>\n",
       "      <td>0.317213</td>\n",
       "      <td>0.299255</td>\n",
       "      <td>0.267844</td>\n",
       "      <td>0.217174</td>\n",
       "      <td>0.212933</td>\n",
       "      <td>0.199504</td>\n",
       "      <td>0.186311</td>\n",
       "      <td>0.177872</td>\n",
       "      <td>0.173773</td>\n",
       "      <td>0.163185</td>\n",
       "      <td>0.144254</td>\n",
       "      <td>0.121686</td>\n",
       "      <td>0.114231</td>\n",
       "      <td>0.108587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>594239</td>\n",
       "      <td>농협비리를 고발합니다</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...</td>\n",
       "      <td>농산어촌</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...</td>\n",
       "      <td>11</td>\n",
       "      <td>1541</td>\n",
       "      <td>[해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, 농사, 재배, 농민, ...</td>\n",
       "      <td>[있, 있, 있, 떠나, 가지, 있, 도와주, 드리, 묻, 따르, 막히, 들추, 지...</td>\n",
       "      <td>[어렵, 낮, 기막히, 없, 없, 싫, 없, 수많]</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>[농협, 비리, 고발]</td>\n",
       "      <td>[농협, 비리, 고발, 해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, ...</td>\n",
       "      <td>{'농협': 0.453, '조합장': 0.449, '농민': 0.383, '운영':...</td>\n",
       "      <td>16.278821</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0</td>\n",
       "      <td>저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...</td>\n",
       "      <td>저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>254</td>\n",
       "      <td>31</td>\n",
       "      <td>3.084112</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>117.615385</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>109.142857</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>512.333333</td>\n",
       "      <td>512.333333</td>\n",
       "      <td>769.000000</td>\n",
       "      <td>7.340187</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.361598</td>\n",
       "      <td>0.247684</td>\n",
       "      <td>0.195276</td>\n",
       "      <td>0.170165</td>\n",
       "      <td>0.154359</td>\n",
       "      <td>0.152217</td>\n",
       "      <td>0.132375</td>\n",
       "      <td>0.129625</td>\n",
       "      <td>0.124780</td>\n",
       "      <td>0.102523</td>\n",
       "      <td>0.102234</td>\n",
       "      <td>0.097638</td>\n",
       "      <td>0.097638</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>585982</td>\n",
       "      <td>4주일간 종교단체 집회를 강력하게 막아 코로나19 확산을 막아주세요</td>\n",
       "      <td>199.0</td>\n",
       "      <td>코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>청원종료</td>\n",
       "      <td>코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...</td>\n",
       "      <td>37</td>\n",
       "      <td>494</td>\n",
       "      <td>[코로나19, 촉발, 국민, 정신, 스트레스, 자영업자, 기업인, 경제, 손실, 가...</td>\n",
       "      <td>[있, 대하, 보, 보, 보이, 어기]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>[주일, 간, 종교, 단체, 집회, 코로나19, 확산]</td>\n",
       "      <td>[주일, 간, 종교, 단체, 집회, 코로나19, 확산, 코로나19, 촉발, 국민, ...</td>\n",
       "      <td>{'종교': 0.473, '단체': 0.399, '집회': 0.397, '주일': ...</td>\n",
       "      <td>10.049876</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...</td>\n",
       "      <td>코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>3.341880</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>494.000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>6.202536</td>\n",
       "      <td>0.868228</td>\n",
       "      <td>0.210139</td>\n",
       "      <td>0.196467</td>\n",
       "      <td>0.139507</td>\n",
       "      <td>0.134073</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>0.109772</td>\n",
       "      <td>0.106944</td>\n",
       "      <td>0.103302</td>\n",
       "      <td>0.098527</td>\n",
       "      <td>0.095707</td>\n",
       "      <td>0.094129</td>\n",
       "      <td>0.091902</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.078351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>908 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       code                                              title     count  \\\n",
       "0    589340                용산 정비창 부지 8,000호 주택공급 계획에 대한 재검토 요청     494.0   \n",
       "1    591390                                 양육비 대지급제 시행을 촉구합니다     362.0   \n",
       "2    588168                               특수상권의 자영업자는 두번 죽습니다.     205.0   \n",
       "3    596255      \"가야고분군\" 세계유산 등재신청에서 남원 유곡리와 두락리고분군은 제외하여 주십시요     128.0   \n",
       "4    584120                  국가어항 슬롭웨이 만큼은 레져보트인이 사용할수 있게 해주세요     552.0   \n",
       "..      ...                                                ...       ...   \n",
       "903  593979  놀다 친구와 부딪힌 사고로 우리집의 6살 슈퍼히어로가 하늘나라로 출동했습니다. 어린...  206063.0   \n",
       "904  589634  '저의 딸이 강간 당하는 것을 목격하여..'  그 충격과 고통으로 딸이 평생 남을 ...  286148.0   \n",
       "905  583065                   신기술의 거부감으로 인한 구시대의 규제를 완화하여 주십시요     218.0   \n",
       "906  594239                                        농협비리를 고발합니다    1275.0   \n",
       "907  585982              4주일간 종교단체 집회를 강력하게 막아 코로나19 확산을 막아주세요     199.0   \n",
       "\n",
       "                                             content_x     category progress  \\\n",
       "0    최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...     교통/건축/국토    청원종료    \n",
       "1    저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....        육아/교육    청원종료    \n",
       "2    아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...         보건복지    청원종료    \n",
       "3    문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...  문화/예술/체육/언론    청원종료    \n",
       "4    우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...         농산어촌    청원종료    \n",
       "..                                                 ...          ...      ...   \n",
       "903  10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...        육아/교육    답변완료    \n",
       "904  국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...       인권/성평등    답변완료    \n",
       "905  국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...         성장동력    청원종료    \n",
       "906  저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...         농산어촌    청원종료    \n",
       "907  코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...         보건복지    청원종료    \n",
       "\n",
       "                                   summary_content_end  title_len  doc_len  \\\n",
       "0    최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...         35     2170   \n",
       "1    저는 남편의 불륜으로 이혼 예정인 워킹맘입니다 사춘기 아이 둘을 둔 엄마이기도 합니...         18     1338   \n",
       "2    아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다 매출이 반 토막보다 더...         20      291   \n",
       "3    문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...         45     2278   \n",
       "4    우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며  그로 인해 레저보트 산업...         33      653   \n",
       "..                                                 ...        ...      ...   \n",
       "903  10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...         96     4083   \n",
       "904  국민청원 사유 저는 성폭행 당한 딸의 엄마입니다 그냥 피눈물이 주르륵 납니다  저의...         98    10232   \n",
       "905  국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...         32     3250   \n",
       "906  저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...         11     1541   \n",
       "907  코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...         37      494   \n",
       "\n",
       "                                          content_noun  \\\n",
       "0    [최근, 용산정, 비창, 부지, 주택, 세대, 건립, 계획, 발표, 여론, 형성, ...   \n",
       "1    [남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아이, 엄마, 그간, 남편, 불륜,...   \n",
       "2    [음식점, 업, 상공, 자영업자, 매출, 토막, 수준, 사정, 국민, 모두, 조금,...   \n",
       "3    [문재인, 대통령, 9월 10일, 문화재, 청, 문화재, 위원회, 세계유산, 분, ...   \n",
       "4    [우리나라, 레져, 보트, 낚시, 인구, 급속, 증가, 추세, 레져, 보트, 산업,...   \n",
       "..                                                 ...   \n",
       "903  [10월 21일, 수요일, 회사, 점심, 식사, 후, 커피, 아이, 어린이집, 전화...   \n",
       "904  [국민, 사유, 성폭행, 딸, 엄마, 피눈물, 딸, 성폭행, 목격, 사건, 분, 본...   \n",
       "905  [국민, 요지, 특허청, 특허, 심사, 진행, 심사, 관, 특허, 명세서, 과학, ...   \n",
       "906  [해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, 농사, 재배, 농민, ...   \n",
       "907  [코로나19, 촉발, 국민, 정신, 스트레스, 자영업자, 기업인, 경제, 손실, 가...   \n",
       "\n",
       "                                          content_verb  \\\n",
       "0    [있, 보, 보, 앞서, 내세우, 되, 나아가, 통하, 돌아가, 엮이, 있, 갚, ...   \n",
       "1    [두, 덮, 모르, 위하, 지키, 속이, 있, 걸, 헤어지, 끊, 돌아오, 보, 참...   \n",
       "2            [있, 더하, 줄어들, 그러, 참, 버티, 버티, 되, 찾, 죽이, 처하]   \n",
       "3    [지나, 지니, 되, 반하, 여기, 지나, 나타나, 보이, 두, 보, 맞, 이루, ...   \n",
       "4    [인하, 되, 위하, 되, 있, 있, 즐기, 있, 있, 대하, 갖, 가, 대하, 쌓...   \n",
       "..                                                 ...   \n",
       "903  [마시, 있, 부딪히, 울, 되, 졸, 자, 일어나, 먹, 토하, 흘리, 가, 보,...   \n",
       "904  [당하, 나, 당하, 덮, 묻, 당하, 덮, 저지르, 저지르, 있, 위하, 넘어가,...   \n",
       "905  [않, 되, 인하, 있, 인하, 대하, 있, 대하, 대하, 있, 달, 있, 대하, ...   \n",
       "906  [있, 있, 있, 떠나, 가지, 있, 도와주, 드리, 묻, 따르, 막히, 들추, 지...   \n",
       "907                              [있, 대하, 보, 보, 보이, 어기]   \n",
       "\n",
       "                                           content_adj      sdays      edays  \\\n",
       "0    [없, 같, 같, 뛰어나, 가깝, 없, 그렇, 많, 어떻, 아름답, 많, 없, 귀하... 2020-05-29 2020-06-28   \n",
       "1                         [그렇, 크, 없, 어떻, 없, 어렵, 없, 어떻] 2020-08-03 2020-09-02   \n",
       "2                                [힘들, 힘들, 같, 같, 작, 힘들] 2020-04-19 2020-05-19   \n",
       "3               [크, 많, 그렇, 다르, 없, 그렇, 넓, 좋, 멀, 안타깝, 없] 2021-02-05 2021-03-07   \n",
       "4                                            [시, 없, 시] 2019-12-20 2020-01-19   \n",
       "..                                                 ...        ...        ...   \n",
       "903  [크, 짧, 같, 적, 적, 없, 이렇, 어떻, 크, 많, 없, 괜찮, 같, 힘들,... 2020-11-13 2020-12-13   \n",
       "904  [많, 없, 그렇, 못되, 못되, 없, 아프, 없, 어이없, 못되, 그렇, 뻔하, ... 2020-06-11 2020-07-11   \n",
       "905      [없, 안타깝, 어렵, 크, 없, 없, 많, 없, 없, 없, 없, 많, 없, 없] 2019-10-11 2019-11-10   \n",
       "906                       [어렵, 낮, 기막히, 없, 없, 싫, 없, 수많] 2020-11-27 2020-12-27   \n",
       "907                                                 [] 2020-03-02 2020-04-01   \n",
       "\n",
       "                                           title_token  \\\n",
       "0              [용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청]   \n",
       "1                                   [양육비, 대지급, 시행, 촉구]   \n",
       "2                                    [특수, 상권, 자영업자, 번]   \n",
       "3    [가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...   \n",
       "4                          [국가, 어항, 만큼, 레져, 보트, 인, 사용]   \n",
       "..                                                 ...   \n",
       "903  [친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...   \n",
       "904  [딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...   \n",
       "905                             [신기술, 거부감, 시대, 규제, 완화]   \n",
       "906                                       [농협, 비리, 고발]   \n",
       "907                     [주일, 간, 종교, 단체, 집회, 코로나19, 확산]   \n",
       "\n",
       "                                           total_token  \\\n",
       "0    [용산, 정, 비창, 부지, 호, 주택, 공급, 계획, 재검토, 요청, 최근, 용산...   \n",
       "1    [양육비, 대지급, 시행, 촉구, 남편, 불륜, 이혼, 예정, 워킹맘, 사춘기, 아...   \n",
       "2    [특수, 상권, 자영업자, 번, 음식점, 업, 상공, 자영업자, 매출, 토막, 수준...   \n",
       "3    [가야, 고분군, 세계유산, 등재, 신청, 남원, 유, 곡리, 두락, 리, 고분군,...   \n",
       "4    [국가, 어항, 만큼, 레져, 보트, 인, 사용, 우리나라, 레져, 보트, 낚시, ...   \n",
       "..                                                 ...   \n",
       "903  [친구, 사고, 우리집, 살, 슈퍼히어로, 하늘나라, 출동, 어린이집, 원, 아, ...   \n",
       "904  [딸, 강간, 목격, 충격, 고통, 딸, 평생, 남, 상처, 가슴, 조작, 부정행위...   \n",
       "905  [신기술, 거부감, 시대, 규제, 완화, 국민, 요지, 특허청, 특허, 심사, 진행...   \n",
       "906  [농협, 비리, 고발, 해, 사레, 복숭아, 충북, 군, 면, 여, 평, 복숭아, ...   \n",
       "907  [주일, 간, 종교, 단체, 집회, 코로나19, 확산, 코로나19, 촉발, 국민, ...   \n",
       "\n",
       "                                           top_keyword  count_noun  \\\n",
       "0    {'용산': 0.391, '국제': 0.31, '입지': 0.266, '부지': 0...   18.654758   \n",
       "1    {'양육비': 0.52, '한부모': 0.441, '이혼': 0.213, '불륜':...   14.106736   \n",
       "2    {'매장': 0.52, '상공': 0.384, '특수': 0.369, '자영업자':...    6.082763   \n",
       "3    {'가야': 0.589, '남원': 0.327, '백제': 0.302, '등재': ...   20.663978   \n",
       "4    {'레져': 0.6, '보트': 0.587, '낚시': 0.152, '어민': 0....   10.583005   \n",
       "..                                                 ...         ...   \n",
       "903  {'어린이집': 0.471, '교사': 0.341, '세바': 0.286, '보육'...   23.937418   \n",
       "904  {'증거': 0.285, '진술': 0.283, '가해자': 0.282, '성폭행'...   39.458839   \n",
       "905  {'심사': 0.402, '특허': 0.397, '특허청': 0.354, '기술':...   23.853721   \n",
       "906  {'농협': 0.453, '조합장': 0.449, '농민': 0.383, '운영':...   16.278821   \n",
       "907  {'종교': 0.473, '단체': 0.399, '집회': 0.397, '주일': ...   10.049876   \n",
       "\n",
       "     count_verb  count_adj  target  \\\n",
       "0      7.810250   4.242641       0   \n",
       "1      7.810250   2.828427       0   \n",
       "2      3.316625   2.449490       0   \n",
       "3      6.082763   3.316625       0   \n",
       "4      4.690416   1.732051       0   \n",
       "..          ...        ...     ...   \n",
       "903   12.961481   6.708204       1   \n",
       "904   16.643317   8.062258       1   \n",
       "905    7.071068   3.741657       0   \n",
       "906    7.071068   2.828427       0   \n",
       "907    2.449490   0.000000       0   \n",
       "\n",
       "                                             content_y  \\\n",
       "0    최근 용산정비창 부지에 주택 8,000세대 건립 계획이 발표되어 다양한 여론이 형성...   \n",
       "1    저는 남편의 불륜으로 이혼예정인 워킹맘입니다.사춘기 아이둘을 둔 엄마이기도 합니다....   \n",
       "2    아울렛 안에서 음식점업을 하고 있는 소상공자영업자 입니다. 매출이 반토막보다 더한 ...   \n",
       "3    문재인 대통령님께 지난 해 9월 10일, 문화재청 문화재위원회 세계유산분과 제5차 ...   \n",
       "4    우리나라 레져보트 낚시인구가 급속하게 증가하는 추세이며.그로인해 레져보트 산업도 발...   \n",
       "..                                                 ...   \n",
       "903  10월 21일 수요일, 회사에서 점심식사 후 커피 마시고 있는데 큰 아이의 어린이집...   \n",
       "904  국민청원 사유  :  저는 성폭행 당한 딸의 엄마입니다.  그냥 피눈물이 주루륵 납...   \n",
       "905  국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은, 특허명세서에서 과학...   \n",
       "906  저는 햇사레복숭아로 유명한 충북 **군 **면에서 10000여평의 복숭아 농사를 재...   \n",
       "907  코로나19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적 ...   \n",
       "\n",
       "                                           pre_content  emotion_angry  \\\n",
       "0    최근 용산정비창 부지에 주택 8 000세대 건립 계획이 발표되어 다양한 여론이 형성...              1   \n",
       "1    저는 남편의 불륜으로 이혼 예정인 워킹맘입니다. 사춘기 아이 둘을 둔 엄마이기도 합...              0   \n",
       "2    아웃렛 안에서 음식점 업을 하고 있는 소상 공자 영업자입니다. 매출이 반 토막보다 ...              0   \n",
       "3    문재인 대통령님께 지난해 9월 10일 문화재청 문화재위원회 세계유산분과 제5차 회의...              1   \n",
       "4    우리나라 레저보트 낚시 인구가 급속하게 증가하는 추세이며. 그로 인해 레저보트 산업...              1   \n",
       "..                                                 ...            ...   \n",
       "903  10월 21일 수요일 회사에서 점심 식사 후 커피 마시고 있는데 큰 아이의 어린이집...              1   \n",
       "904  국민청원 사유 저는 성폭행 당한 딸의 엄마입니다. 그냥 피눈물이 주르륵 납니다. 저...              0   \n",
       "905  국민청원의 요지 현재 특허청에서 특허심사를 진행하는 심사관들은 특허명세서에서 과학적...              0   \n",
       "906  저는 햇사레 복숭아로 유명한 충북 군 면에서 10000여 평의 복숭아 농사를 재배하...              1   \n",
       "907  코로나 19로 촉발된 국민들의 정신적인 스트레스와 자영업자는 물론 기업인들의 경제적...              1   \n",
       "\n",
       "     emotion_disgust  emotion_dontknow  emotion_fear  emotion_sad  num_words  \\\n",
       "0                  0                 0             0            0        519   \n",
       "1                  1                 0             0            0        343   \n",
       "2                  0                 0             0            1         72   \n",
       "3                  0                 0             0            0        519   \n",
       "4                  0                 0             0            0        153   \n",
       "..               ...               ...           ...          ...        ...   \n",
       "903                0                 0             0            0       1053   \n",
       "904                0                 0             0            1       2417   \n",
       "905                0                 0             0            1        712   \n",
       "906                0                 0             0            0        321   \n",
       "907                0                 0             0            0        117   \n",
       "\n",
       "     num_unique_words  num_punctuations  mean_word_len  title_mean_word_len  \\\n",
       "0                 439                62       3.165703             3.000000   \n",
       "1                 290                44       3.128280             3.750000   \n",
       "2                  66                 5       3.138889             4.250000   \n",
       "3                 417                55       3.281310             4.750000   \n",
       "4                 131                21       3.084967             3.857143   \n",
       "..                ...               ...            ...                  ...   \n",
       "903               762               152       2.898386             3.409091   \n",
       "904              1254               576       2.927596             3.217391   \n",
       "905               457               151       3.526685             3.714286   \n",
       "906               254                31       3.084112             5.000000   \n",
       "907               106                 4       3.341880             3.750000   \n",
       "\n",
       "               ,        ;             \"       ...         ?            !  \\\n",
       "0      97.681818   2170.0   2170.000000  2170.000   216.100  2170.000000   \n",
       "1    1338.000000   1338.0   1338.000000   332.250   166.375  1338.000000   \n",
       "2     291.000000    291.0    291.000000   291.000   291.000   291.000000   \n",
       "3     107.523810   2278.0    454.800000  2278.000  2278.000  2278.000000   \n",
       "4     217.000000    653.0    653.000000   653.000   653.000   653.000000   \n",
       "..           ...      ...           ...       ...       ...          ...   \n",
       "903    51.358974   4083.0   4083.000000  4083.000  4083.000  4083.000000   \n",
       "904   111.450549  10232.0  10232.000000  1276.375   681.200   351.862069   \n",
       "905    55.051724   3250.0    360.222222  3250.000  3250.000  3250.000000   \n",
       "906   770.000000   1541.0   1541.000000  1541.000  1541.000  1541.000000   \n",
       "907   246.500000    494.0    494.000000   494.000   494.000   494.000000   \n",
       "\n",
       "              .            :            *            -        ■            ★  \\\n",
       "0     66.843750  2170.000000  2170.000000  1084.500000   2170.0  2170.000000   \n",
       "1     37.257143  1338.000000  1338.000000  1338.000000   1338.0  1338.000000   \n",
       "2     47.666667   291.000000   291.000000   291.000000    291.0   291.000000   \n",
       "3    125.611111  2278.000000   568.750000  2278.000000   2278.0  2278.000000   \n",
       "4     53.500000   653.000000    92.428571   653.000000    653.0   653.000000   \n",
       "..          ...          ...          ...          ...      ...          ...   \n",
       "903   76.056604  2041.000000  4083.000000   679.666667   4083.0  4083.000000   \n",
       "904   80.214286   408.320000   261.384615   291.371429  10232.0   600.941176   \n",
       "905   84.552632  1082.666667  3250.000000   170.105263   3250.0  3250.000000   \n",
       "906  117.615385   770.000000   109.142857  1541.000000   1541.0  1541.000000   \n",
       "907  494.000000   494.000000   494.000000   494.000000    494.0   494.000000   \n",
       "\n",
       "           @       please          chu         moon   log_doc         0  \\\n",
       "0     2170.0  2170.000000  2170.000000  2170.000000  7.682482  0.424290   \n",
       "1     1338.0   668.000000  1338.000000   444.000000  7.198931  0.438849   \n",
       "2      291.0   291.000000   291.000000   291.000000  5.673323  0.731018   \n",
       "3     2278.0  2278.000000   568.000000   453.200000  7.731053  0.618037   \n",
       "4      653.0   325.500000   325.500000   653.000000  6.481577  0.521381   \n",
       "..       ...          ...          ...          ...       ...       ...   \n",
       "903   4083.0  2040.500000  2040.500000  4083.000000  8.314587  0.663262   \n",
       "904  10232.0  2044.800000  3409.333333  1702.833333  9.233275  0.410463   \n",
       "905   3250.0  3250.000000   811.000000  3250.000000  8.086410  0.519996   \n",
       "906   1541.0   512.333333   512.333333   769.000000  7.340187  0.675732   \n",
       "907    494.0   494.000000   494.000000   494.000000  6.202536  0.868228   \n",
       "\n",
       "            1         2         3         4         5         6         7  \\\n",
       "0    0.400065  0.371941  0.337048  0.313815  0.256219  0.216296  0.133494   \n",
       "1    0.395796  0.358760  0.231779  0.229750  0.199950  0.168115  0.155442   \n",
       "2    0.524812  0.301879  0.221965  0.180084  0.131738  0.000000  0.000000   \n",
       "3    0.419106  0.249285  0.209501  0.202697  0.188087  0.170882  0.169267   \n",
       "4    0.518109  0.275852  0.226562  0.210827  0.157344  0.140396  0.130866   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "903  0.489153  0.314064  0.264960  0.159139  0.144487  0.125898  0.106700   \n",
       "904  0.376792  0.358840  0.316025  0.299607  0.275842  0.261490  0.245893   \n",
       "905  0.317213  0.299255  0.267844  0.217174  0.212933  0.199504  0.186311   \n",
       "906  0.361598  0.247684  0.195276  0.170165  0.154359  0.152217  0.132375   \n",
       "907  0.210139  0.196467  0.139507  0.134073  0.129021  0.109772  0.106944   \n",
       "\n",
       "            8         9        10        11        12        13        14  \n",
       "0    0.126287  0.126137  0.118307  0.117249  0.102693  0.077471  0.076537  \n",
       "1    0.149731  0.149731  0.147303  0.144989  0.129855  0.123611  0.108876  \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3    0.150096  0.138120  0.118363  0.082100  0.078059  0.076876  0.076124  \n",
       "4    0.129832  0.124611  0.124171  0.123307  0.115629  0.114943  0.109148  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "903  0.088170  0.072542  0.071560  0.062324  0.057353  0.052409  0.049074  \n",
       "904  0.182428  0.152785  0.115450  0.093620  0.090161  0.080589  0.077447  \n",
       "905  0.177872  0.173773  0.163185  0.144254  0.121686  0.114231  0.108587  \n",
       "906  0.129625  0.124780  0.102523  0.102234  0.097638  0.097638  0.096200  \n",
       "907  0.103302  0.098527  0.095707  0.094129  0.091902  0.085644  0.078351  \n",
       "\n",
       "[908 rows x 65 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2 = pd.concat([train_df,train_tfidf_df], axis = 1)\n",
    "train_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df,train_tfidf_df], axis = 1)\n",
    "test_df = pd.concat([test_df,test_tfidf_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code         0\n",
       "title        0\n",
       "count        0\n",
       "content_x    0\n",
       "category     0\n",
       "            ..\n",
       "10           0\n",
       "11           0\n",
       "12           0\n",
       "13           0\n",
       "14           0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "train_df = train_df.reset_index(drop =True) \n",
    "test_df = test_df.reset_index(drop =True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"train_df.pkl\")\n",
    "test_df.to_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['target']\n",
    "\n",
    "cols_to_drop = ['count','progress','doc_len','total_token','category','top_keyword','code', 'pre_content','content_y','content_x','title','summary_content_end','content_noun','content_verb','content_adj','sdays','edays','title_token']\n",
    "train_X = train_df.drop(cols_to_drop+['target'], axis=1)\n",
    "test_X = test_df.drop(cols_to_drop+['target'], axis=1)\n",
    "test_y = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(908, 46)\n",
      "(228, 46)\n",
      "(908,)\n",
      "(228,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 모델설정\n",
    "sm = SMOTE()\n",
    "\n",
    "# train데이터를 넣어 복제함\n",
    "X_resampled, y_resampled = sm.fit_sample(train_X,list(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([          'title_len',          'count_noun',          'count_verb',\n",
       "                 'count_adj',       'emotion_angry',     'emotion_disgust',\n",
       "          'emotion_dontknow',        'emotion_fear',         'emotion_sad',\n",
       "                 'num_words',    'num_unique_words',    'num_punctuations',\n",
       "             'mean_word_len', 'title_mean_word_len',                   ',',\n",
       "                         ';',                   '\"',                 '...',\n",
       "                         '?',                   '!',                   '.',\n",
       "                         ':',                   '*',                   '-',\n",
       "                         '■',                   '★',                   '@',\n",
       "                    'please',                 'chu',                'moon',\n",
       "                   'log_doc',                     0,                     1,\n",
       "                           2,                     3,                     4,\n",
       "                           5,                     6,                     7,\n",
       "                           8,                     9,                    10,\n",
       "                          11,                    12,                    13,\n",
       "                          14],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([          'title_len',          'count_noun',          'count_verb',\n",
       "                 'count_adj',       'emotion_angry',     'emotion_disgust',\n",
       "          'emotion_dontknow',        'emotion_fear',         'emotion_sad',\n",
       "                 'num_words',    'num_unique_words',    'num_punctuations',\n",
       "             'mean_word_len', 'title_mean_word_len',                   ',',\n",
       "                         ';',                   '\"',                 '...',\n",
       "                         '?',                   '!',                   '.',\n",
       "                         ':',                   '*',                   '-',\n",
       "                         '■',                   '★',                   '@',\n",
       "                    'please',                 'chu',                'moon',\n",
       "                   'log_doc',                     0,                     1,\n",
       "                           2,                     3,                     4,\n",
       "                           5,                     6,                     7,\n",
       "                           8,                     9,                    10,\n",
       "                          11,                    12,                    13,\n",
       "                          14],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "RNG = 42\n",
    "\n",
    "\n",
    "metric_names = ['f1', 'roc_auc', 'average_precision', 'accuracy', 'precision', 'recall']\n",
    "scores_df = pd.DataFrame(index=metric_names, columns=['Random-CV', 'Stratified-CV']) # to store the scores\n",
    "cv = KFold(n_splits=3)\n",
    "scv = StratifiedKFold(n_splits=3)\n",
    "clf = RandomForestClassifier()\n",
    "for metric in metric_names:\n",
    "    score1 = cross_val_score(clf, train_X, train_y, scoring=metric, cv=cv).mean()\n",
    "    score2 = cross_val_score(clf, train_X, train_y, scoring=metric, cv=scv).mean()\n",
    "    scores_df.loc[metric] = [score1, score2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random-CV</th>\n",
       "      <th>Stratified-CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.0190476</td>\n",
       "      <td>0.035112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.560754</td>\n",
       "      <td>0.612837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision</th>\n",
       "      <td>0.20605</td>\n",
       "      <td>0.217743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.882139</td>\n",
       "      <td>0.878857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.00980392</td>\n",
       "      <td>0.0185185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Random-CV Stratified-CV\n",
       "f1                  0.0190476      0.035112\n",
       "roc_auc              0.560754      0.612837\n",
       "average_precision     0.20605      0.217743\n",
       "accuracy             0.882139      0.878857\n",
       "precision            0.333333             0\n",
       "recall             0.00980392     0.0185185"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_weight = {1: 0.85,\n",
    "                0: 0.15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15/15 [==============================] - 2s 3ms/step - loss: 182.9652 - accuracy: 0.8884\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 92.6476 - accuracy: 0.8738\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 39.4033 - accuracy: 0.4613\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 25.8313 - accuracy: 0.2752\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 15.4010 - accuracy: 0.4235\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 16.6720 - accuracy: 0.3893\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 15.8395 - accuracy: 0.4169\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 13.6230 - accuracy: 0.4190\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 11.0071 - accuracy: 0.6076\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.8852 - accuracy: 0.6746\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.5552 - accuracy: 0.6226\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 4.0939 - accuracy: 0.6770\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 4.0185 - accuracy: 0.3821\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.9570 - accuracy: 0.5599\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.7101 - accuracy: 0.6933\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.2595 - accuracy: 0.6486\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7560 - accuracy: 0.5847\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6184 - accuracy: 0.6353\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7132 - accuracy: 0.6330\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5957 - accuracy: 0.5188\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5543 - accuracy: 0.6554\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4101 - accuracy: 0.5344\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4908 - accuracy: 0.5748\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1679 - accuracy: 0.6247\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5527 - accuracy: 0.6669\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3538 - accuracy: 0.6416\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4123 - accuracy: 0.4791\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0603 - accuracy: 0.6116\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9357 - accuracy: 0.5777\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2052 - accuracy: 0.5329\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2694 - accuracy: 0.5657\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7649 - accuracy: 0.4757\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2136 - accuracy: 0.6604\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6081 - accuracy: 0.5673\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0645 - accuracy: 0.5588\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1250 - accuracy: 0.4693\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9140 - accuracy: 0.7073\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.6101\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8057 - accuracy: 0.5720\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.6528\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6704\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.6415 - accuracy: 0.3973\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4127 - accuracy: 0.6872\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7498\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8074 - accuracy: 0.6889\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8816 - accuracy: 0.6830\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.6983\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9465 - accuracy: 0.5705\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.6896\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.5637\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.6570\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7167\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.6690\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9452 - accuracy: 0.4319\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1683 - accuracy: 0.7249\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.6465\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7809 - accuracy: 0.6618\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6938\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8949 - accuracy: 0.5032\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7107\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.6214\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0712 - accuracy: 0.6715\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7045\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7913 - accuracy: 0.5644\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1823 - accuracy: 0.4829\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.6796\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.6908\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.6642\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.7678\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8564 - accuracy: 0.5476\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6561\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6270\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8762 - accuracy: 0.5012\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.5930\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.6707\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.6716\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.6459\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.6549\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.6940\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.5118\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.5956\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.6626\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.9383 - accuracy: 0.3343\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1393 - accuracy: 0.6916\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7149\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.5166\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.6499\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7540 - accuracy: 0.6584\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0475 - accuracy: 0.7412\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9683 - accuracy: 0.4908\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4992 - accuracy: 0.4513\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2959 - accuracy: 0.5032\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1317 - accuracy: 0.7690\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7223 - accuracy: 0.5619\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.5306\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6548 - accuracy: 0.6959\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.6232\n",
      "Epoch 98/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.6237\n",
      "Epoch 99/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6526\n",
      "Epoch 100/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.7336\n",
      "Epoch 101/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8696 - accuracy: 0.4574\n",
      "Epoch 102/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.5634\n",
      "Epoch 103/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7239\n",
      "Epoch 104/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.6269\n",
      "Epoch 105/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6795 - accuracy: 0.3700\n",
      "Epoch 106/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2276 - accuracy: 0.7353\n",
      "Epoch 107/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7340\n",
      "Epoch 108/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.6204\n",
      "Epoch 109/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.6038\n",
      "Epoch 110/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3668 - accuracy: 0.6848\n",
      "Epoch 111/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.7403\n",
      "Epoch 112/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.7662\n",
      "Epoch 113/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.6955\n",
      "Epoch 114/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.7156\n",
      "Epoch 115/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.6454\n",
      "Epoch 116/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.6795\n",
      "Epoch 117/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.6584\n",
      "Epoch 118/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2148 - accuracy: 0.6392\n",
      "Epoch 119/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0372 - accuracy: 0.7441\n",
      "Epoch 120/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.6807\n",
      "Epoch 121/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.6442\n",
      "Epoch 122/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.6842\n",
      "Epoch 123/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7378 - accuracy: 0.4741\n",
      "Epoch 124/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.6070\n",
      "Epoch 125/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7063\n",
      "Epoch 126/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.6355\n",
      "Epoch 127/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.5918\n",
      "Epoch 128/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.3434 - accuracy: 0.3434\n",
      "Epoch 129/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9094 - accuracy: 0.7979\n",
      "Epoch 130/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7467 - accuracy: 0.5968\n",
      "Epoch 131/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.6948\n",
      "Epoch 132/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7930 - accuracy: 0.6549\n",
      "Epoch 133/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.7362\n",
      "Epoch 134/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7903 - accuracy: 0.7340\n",
      "Epoch 135/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.7485\n",
      "Epoch 136/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.6676\n",
      "Epoch 137/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.6450\n",
      "Epoch 138/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.5546\n",
      "Epoch 139/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0277 - accuracy: 0.5204\n",
      "Epoch 140/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7267\n",
      "Epoch 141/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9928 - accuracy: 0.4928\n",
      "Epoch 142/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.6288\n",
      "Epoch 143/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4792 - accuracy: 0.4666\n",
      "Epoch 144/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0332 - accuracy: 0.7157\n",
      "Epoch 145/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.4537\n",
      "Epoch 146/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3498 - accuracy: 0.7373\n",
      "Epoch 147/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.5610\n",
      "Epoch 148/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2468 - accuracy: 0.4414\n",
      "Epoch 149/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7332 - accuracy: 0.6835\n",
      "Epoch 150/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.5429\n",
      "Epoch 151/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.7249\n",
      "Epoch 152/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8115 - accuracy: 0.6364\n",
      "Epoch 153/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.6610\n",
      "Epoch 154/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.6905\n",
      "Epoch 155/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.5569\n",
      "Epoch 156/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6009\n",
      "Epoch 157/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.6699\n",
      "Epoch 158/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.7006\n",
      "Epoch 159/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.6916\n",
      "Epoch 160/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.5410\n",
      "Epoch 161/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.6227\n",
      "Epoch 162/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.7113\n",
      "Epoch 163/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.6935\n",
      "Epoch 164/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7271 - accuracy: 0.5109\n",
      "Epoch 165/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.7123\n",
      "Epoch 166/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.6618\n",
      "Epoch 167/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.5476\n",
      "Epoch 168/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.6356\n",
      "Epoch 169/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.7622\n",
      "Epoch 170/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.6608\n",
      "Epoch 171/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6811\n",
      "Epoch 172/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.4836\n",
      "Epoch 173/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.7345\n",
      "Epoch 174/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7104\n",
      "Epoch 175/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.5820\n",
      "Epoch 176/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.7629\n",
      "Epoch 177/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.7557\n",
      "Epoch 178/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.6214\n",
      "Epoch 179/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.7983\n",
      "Epoch 180/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.7069\n",
      "Epoch 181/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.6127\n",
      "Epoch 182/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.7790\n",
      "Epoch 183/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.7171\n",
      "Epoch 184/300\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3443 - accuracy: 0.6787\n",
      "Epoch 185/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7261\n",
      "Epoch 186/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.6370\n",
      "Epoch 187/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0748 - accuracy: 0.6930\n",
      "Epoch 188/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.7003\n",
      "Epoch 189/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7158\n",
      "Epoch 190/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.6417\n",
      "Epoch 191/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.6811\n",
      "Epoch 192/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.6275\n",
      "Epoch 193/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6140\n",
      "Epoch 194/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.6019\n",
      "Epoch 195/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7129\n",
      "Epoch 196/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9112 - accuracy: 0.4691\n",
      "Epoch 197/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9174 - accuracy: 0.7043\n",
      "Epoch 198/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7429 - accuracy: 0.6433\n",
      "Epoch 199/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6706\n",
      "Epoch 200/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.6739\n",
      "Epoch 201/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8931 - accuracy: 0.7291\n",
      "Epoch 202/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9945 - accuracy: 0.6397\n",
      "Epoch 203/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.7461\n",
      "Epoch 204/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.6990\n",
      "Epoch 205/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.5854\n",
      "Epoch 206/300\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.68 - 0s 2ms/step - loss: 0.2342 - accuracy: 0.7061\n",
      "Epoch 207/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.6058\n",
      "Epoch 208/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1841 - accuracy: 0.6522\n",
      "Epoch 209/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7890\n",
      "Epoch 210/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.6611\n",
      "Epoch 211/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.5937\n",
      "Epoch 212/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.6745\n",
      "Epoch 213/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.6995\n",
      "Epoch 214/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.6604\n",
      "Epoch 215/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.6902\n",
      "Epoch 216/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.6768\n",
      "Epoch 217/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.7103\n",
      "Epoch 218/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.6995\n",
      "Epoch 219/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.6587\n",
      "Epoch 220/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.7197\n",
      "Epoch 221/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.6944\n",
      "Epoch 222/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.7660\n",
      "Epoch 223/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.7595\n",
      "Epoch 224/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.6811\n",
      "Epoch 225/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.5265\n",
      "Epoch 226/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9166 - accuracy: 0.5120\n",
      "Epoch 227/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8046\n",
      "Epoch 228/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.6885\n",
      "Epoch 229/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.3791 - accuracy: 0.3402\n",
      "Epoch 230/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.7853\n",
      "Epoch 231/300\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.64 - 0s 2ms/step - loss: 0.3829 - accuracy: 0.6403\n",
      "Epoch 232/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.7127\n",
      "Epoch 233/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.6057\n",
      "Epoch 234/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.6204\n",
      "Epoch 235/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7118\n",
      "Epoch 236/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6624\n",
      "Epoch 237/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.6483\n",
      "Epoch 238/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.6296\n",
      "Epoch 239/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.7550\n",
      "Epoch 240/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.7047\n",
      "Epoch 241/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.7196\n",
      "Epoch 242/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.6097\n",
      "Epoch 243/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7195\n",
      "Epoch 244/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.7172\n",
      "Epoch 245/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.6631\n",
      "Epoch 246/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.7497\n",
      "Epoch 247/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.7018\n",
      "Epoch 248/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.6314\n",
      "Epoch 249/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7179\n",
      "Epoch 250/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.5053\n",
      "Epoch 251/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6432\n",
      "Epoch 252/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.7590\n",
      "Epoch 253/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.6190\n",
      "Epoch 254/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.7277\n",
      "Epoch 255/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.7797\n",
      "Epoch 256/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.5921\n",
      "Epoch 257/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.6803\n",
      "Epoch 258/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.7201\n",
      "Epoch 259/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.6639\n",
      "Epoch 260/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.7117\n",
      "Epoch 261/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.6617\n",
      "Epoch 262/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.7506\n",
      "Epoch 263/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.5215\n",
      "Epoch 264/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.6929\n",
      "Epoch 265/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.5403\n",
      "Epoch 266/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.6915\n",
      "Epoch 267/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.6608\n",
      "Epoch 268/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.7242\n",
      "Epoch 269/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9243 - accuracy: 0.5965\n",
      "Epoch 270/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5088 - accuracy: 0.7472\n",
      "Epoch 271/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8476 - accuracy: 0.5610\n",
      "Epoch 272/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.7418\n",
      "Epoch 273/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.6548\n",
      "Epoch 274/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.7331\n",
      "Epoch 275/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.6634\n",
      "Epoch 276/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7009\n",
      "Epoch 277/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.5208\n",
      "Epoch 278/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.6982\n",
      "Epoch 279/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.7010\n",
      "Epoch 280/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.5752\n",
      "Epoch 281/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.7296\n",
      "Epoch 282/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8110 - accuracy: 0.6089\n",
      "Epoch 283/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7634\n",
      "Epoch 284/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7460 - accuracy: 0.5418\n",
      "Epoch 285/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.6769\n",
      "Epoch 286/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.6515\n",
      "Epoch 287/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.6824\n",
      "Epoch 288/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8302 - accuracy: 0.5273\n",
      "Epoch 289/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.6671\n",
      "Epoch 290/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9268 - accuracy: 0.4859\n",
      "Epoch 291/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.6030\n",
      "Epoch 292/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.7707\n",
      "Epoch 293/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9960 - accuracy: 0.4907\n",
      "Epoch 294/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.6171\n",
      "Epoch 295/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5569 - accuracy: 0.4747\n",
      "Epoch 296/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.6729\n",
      "Epoch 297/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7309\n",
      "Epoch 298/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.6905\n",
      "Epoch 299/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.6836\n",
      "Epoch 300/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.6822\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-1a3b302f90e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Misclassified Samples:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=46, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=300, batch_size=64, class_weight= class_weight)\n",
    "\n",
    "\n",
    "print('Misclassified Samples:', (Y != Y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_classes(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       171\n",
      "           1       0.30      0.14      0.19        57\n",
      "\n",
      "    accuracy                           0.70       228\n",
      "   macro avg       0.53      0.51      0.50       228\n",
      "weighted avg       0.64      0.70      0.66       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_pred, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_resampled)\n",
    "scaled_X_train = scaler.transform(X_resampled)\n",
    "scaled_X_test = scaler.fit_transform(test_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # 분류\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "def Modeling_result(train_x, train_y, valid_x, valid_y):\n",
    "    \n",
    "    models = [LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier(), XGBClassifier(),KNeighborsClassifier(n_neighbors=4)]\n",
    "    names = [\"Logistic\",\"RF\",\"Ada\",\"XGB\",\"KNN\"]\n",
    "\n",
    "    train_acc = []\n",
    "    train_precision = []\n",
    "    train_recall = []\n",
    "    train_roc = []\n",
    "    train_f1 = []\n",
    "\n",
    "    valid_acc = []\n",
    "    valid_precision = []\n",
    "    valid_recall = []\n",
    "    valid_roc = []\n",
    "    valid_f1 = []\n",
    "\n",
    "    for model, name in zip(models, names):\n",
    "\n",
    "        model.fit(train_x,train_y)\n",
    "        model.predict(valid_x)\n",
    "\n",
    "        train_acc.append(accuracy_score(train_y,model.predict(train_x)))\n",
    "        train_precision.append(precision_score(train_y,model.predict(train_x)))\n",
    "        train_recall.append(recall_score(train_y,model.predict(train_x)))\n",
    "        train_roc.append(roc_auc_score(train_y, model.predict(train_x)))\n",
    "        train_f1.append(f1_score(train_y, model.predict(train_x)))\n",
    "\n",
    "        valid_acc.append(accuracy_score(valid_y, model.predict(valid_x)))\n",
    "        valid_precision.append(precision_score(valid_y,model.predict(valid_x)))\n",
    "        valid_recall.append(recall_score(valid_y,model.predict(valid_x)))\n",
    "        valid_roc.append(roc_auc_score(valid_y, model.predict(valid_x)))\n",
    "        valid_f1.append(f1_score(valid_y, model.predict(valid_x)))\n",
    "        \n",
    "    return pd.DataFrame({\"Model\":names, \"Train_Accuracy\":train_acc, \"Train_Precision\":train_precision, \"Train_Recall\":train_recall, \"Train_AUC\":train_roc, \"Train_F1\":train_f1,\n",
    "             \"Valid_Accuracy\":valid_acc, \"Valid_Precision\":valid_precision, \"Valid_Recall\":valid_recall, \"Valid_AUC\":valid_roc, \"Valid_F1\":valid_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 46)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:30:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Valid_Accuracy</th>\n",
       "      <th>Valid_Precision</th>\n",
       "      <th>Valid_Recall</th>\n",
       "      <th>Valid_AUC</th>\n",
       "      <th>Valid_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.828536</td>\n",
       "      <td>0.898331</td>\n",
       "      <td>0.740926</td>\n",
       "      <td>0.828536</td>\n",
       "      <td>0.812071</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.139037</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.580984</td>\n",
       "      <td>0.242991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.535379</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ada</td>\n",
       "      <td>0.886108</td>\n",
       "      <td>0.895006</td>\n",
       "      <td>0.874844</td>\n",
       "      <td>0.886108</td>\n",
       "      <td>0.884810</td>\n",
       "      <td>0.662281</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.487839</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.522941</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.938673</td>\n",
       "      <td>0.907085</td>\n",
       "      <td>0.977472</td>\n",
       "      <td>0.938673</td>\n",
       "      <td>0.940964</td>\n",
       "      <td>0.675439</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.495301</td>\n",
       "      <td>0.159091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Train_Accuracy  Train_Precision  Train_Recall  Train_AUC  \\\n",
       "0  Logistic        0.828536         0.898331      0.740926   0.828536   \n",
       "1        RF        1.000000         1.000000      1.000000   1.000000   \n",
       "2       Ada        0.886108         0.895006      0.874844   0.886108   \n",
       "3       XGB        1.000000         1.000000      1.000000   1.000000   \n",
       "4       KNN        0.938673         0.907085      0.977472   0.938673   \n",
       "\n",
       "   Train_F1  Valid_Accuracy  Valid_Precision  Valid_Recall  Valid_AUC  \\\n",
       "0  0.812071        0.289474         0.139037      0.962963   0.580984   \n",
       "1  1.000000        0.802632         0.178571      0.185185   0.535379   \n",
       "2  0.884810        0.662281         0.109375      0.259259   0.487839   \n",
       "3  1.000000        0.780702         0.151515      0.185185   0.522941   \n",
       "4  0.940964        0.675439         0.114754      0.259259   0.495301   \n",
       "\n",
       "   Valid_F1  \n",
       "0  0.242991  \n",
       "1  0.181818  \n",
       "2  0.153846  \n",
       "3  0.166667  \n",
       "4  0.159091  "
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_right = Modeling_result(scaled_X_train, y_resampled, scaled_X_test, test_y)\n",
    "gender_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:30:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Valid_Accuracy</th>\n",
       "      <th>Valid_Precision</th>\n",
       "      <th>Valid_Recall</th>\n",
       "      <th>Valid_AUC</th>\n",
       "      <th>Valid_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.608886</td>\n",
       "      <td>0.599315</td>\n",
       "      <td>0.657071</td>\n",
       "      <td>0.608886</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.530702</td>\n",
       "      <td>0.122642</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.509397</td>\n",
       "      <td>0.195489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.549198</td>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ada</td>\n",
       "      <td>0.886108</td>\n",
       "      <td>0.895006</td>\n",
       "      <td>0.874844</td>\n",
       "      <td>0.886108</td>\n",
       "      <td>0.884810</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.489497</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846491</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.544223</td>\n",
       "      <td>0.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.922403</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.979975</td>\n",
       "      <td>0.922403</td>\n",
       "      <td>0.926627</td>\n",
       "      <td>0.706140</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.464621</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Train_Accuracy  Train_Precision  Train_Recall  Train_AUC  \\\n",
       "0  Logistic        0.608886         0.599315      0.657071   0.608886   \n",
       "1        RF        1.000000         1.000000      1.000000   1.000000   \n",
       "2       Ada        0.886108         0.895006      0.874844   0.886108   \n",
       "3       XGB        1.000000         1.000000      1.000000   1.000000   \n",
       "4       KNN        0.922403         0.878788      0.979975   0.922403   \n",
       "\n",
       "   Train_F1  Valid_Accuracy  Valid_Precision  Valid_Recall  Valid_AUC  \\\n",
       "0  0.626866        0.530702         0.122642      0.481481   0.509397   \n",
       "1  1.000000        0.855263         0.285714      0.148148   0.549198   \n",
       "2  0.884810        0.750000         0.105263      0.148148   0.489497   \n",
       "3  1.000000        0.846491         0.250000      0.148148   0.544223   \n",
       "4  0.926627        0.706140         0.083333      0.148148   0.464621   \n",
       "\n",
       "   Valid_F1  \n",
       "0  0.195489  \n",
       "1  0.195122  \n",
       "2  0.123077  \n",
       "3  0.186047  \n",
       "4  0.106667  "
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_right = Modeling_result(X_resampled, y_resampled, test_X, test_y)\n",
    "gender_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4) #K최근접이웃\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)#랜덤포레스트\n",
    "xgb_clf = XGBClassifier() #결정트리\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100) #아다부스트\n",
    "\n",
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_training, y_training)  \n",
    "rf_clf.fit(X_training , y_training)  \n",
    "xgb_clf.fit(X_training , y_training)\n",
    "ada_clf.fit(X_training, y_training)\n",
    "\n",
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(test_X)\n",
    "rf_pred = rf_clf.predict(test_X)\n",
    "xgb_pred = xgb_clf.predict(test_X)\n",
    "ada_pred = ada_clf.predict(test_X)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_testing, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_testing, rf_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_testing, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f} :'.format(accuracy_score(y_testing, ada_pred)))\n",
    "\n",
    "# 시험데이터로 예측한 4가지 모델의 결과를 합침\n",
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. \n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)\n",
    "\n",
    "# 최종 분류기 모델 생성\n",
    "lr_final = LogisticRegression(C=10)\n",
    "\n",
    "# 최종 분류기 학습 및 예측\n",
    "lr_final.fit(pred, y_testing)\n",
    "final = lr_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_testing , final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.82      0.86      0.84        21\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.41      0.43      0.42        25\n",
      "weighted avg       0.69      0.72      0.70        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(np.array(X_resampled), y_resampled)\n",
    "pred = clf.predict(test_X)\n",
    "\n",
    "print(classification_report(pred, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(test_X)], axis = 0) \n",
    "# y_cv = pd.concat([pd.DataFrame(y_resampled), pd.DataFrame(test_y)], axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv = sum([y_resampled+test_y.tolist()], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\" :[10,15,20,25], \n",
    "    \"max_depth\" : [5,10,15],\n",
    "    \"min_samples_split\":[2,4,8,16],\n",
    "    \"max_features\":[\"sqrt\",\"auto\",\"log2\"],\n",
    "    \"class_weight\" : [\"balanced_subsample\",\"balanced\"]}\n",
    "\n",
    "cv_RF_roc = GridSearchCV(RandomForestClassifier(),param_grid_RF, cv= 10, scoring = \"roc_auc\",return_train_score=True)\n",
    "cv_RF_roc.fit(X_cv, y_cv)\n",
    "cv_RF_best = cv_RF_roc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 25}"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_gradient</td>\n",
       "      <td>0.875576</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.873395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy  Precision    Recall       AUC\n",
       "0  RF_gradient  0.875576   0.876033  0.898305  0.873395"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = cv_RF_roc.best_params_\n",
    "model_RF = RandomForestClassifier(class_weight = \"balanced\",max_depth = 15, max_features = 'sqrt', min_samples_split = 2, n_estimators = 25, random_state = 20171490)\n",
    "\n",
    "# method{'predict’,'predict_proba’, 'predict_log_proba’, 'decision_function'}, default=’predict’\n",
    "cv_predict = cross_val_predict(model_RF, X_cv, y_cv, cv=10)\n",
    "\n",
    "acc = accuracy_score(y_cv, cv_predict)\n",
    "precision = precision_score(y_cv,cv_predict)\n",
    "recall = recall_score(y_cv,cv_predict)\n",
    "roc =roc_auc_score(y_cv, cv_predict)\n",
    "\n",
    "pd.DataFrame([{\"Model\":\"RF_gradient\",\"Accuracy\":acc, \"Precision\":precision, \"Recall\":recall, \"AUC\":roc}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sns.heatmap(confusion_matrix(cv_predict, y_cv),annot=True,fmt='3.0f',cmap=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ada=AdaBoostClassifier()\n",
    "search_grid={'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1]}\n",
    "grid_search_ABC=GridSearchCV(estimator=ada,param_grid=search_grid,scoring='accuracy',n_jobs=1)\n",
    "\n",
    "# run grid search\n",
    "grid_search_ABC.fit(X_cv, y_cv)\n",
    "cv_Ada_best = grid_search_ABC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.01, n_estimators=1000)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [908, 131]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-396-bd063ffd7ebe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhelp_train_feat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhelp_test_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mhelp_train_feat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhelp_test_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_nb_feats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[0mhelp_train_feat2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhelp_test_feat2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_nb_feats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0mhelp_train_feat3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhelp_test_feat3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_nb_feats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-396-bd063ffd7ebe>\u001b[0m in \u001b[0;36mgen_nb_feats\u001b[1;34m(rnd)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mskf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeat_cnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrnd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tfidf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m# tfidf to nb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_tfidf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_tfidf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \"\"\"\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 256\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [908, 131]"
     ]
    }
   ],
   "source": [
    "# add naive feature\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "feat_cnt = 5\n",
    "train_Y = train_y\n",
    "\n",
    "def gen_nb_feats(rnd=1):\n",
    "    \n",
    "    help_tfidf_train,help_tfidf_test = np.zeros((54879,5)),np.zeros((19617,5))\n",
    "    help_tfidf_train2,help_tfidf_test2 = np.zeros((54879,5)),np.zeros((19617,5))\n",
    "    help_cnt1_train,help_cnt1_test = np.zeros((54879,5)),np.zeros((19617,5))\n",
    "    help_cnt2_train,help_cnt2_test = np.zeros((54879,5)),np.zeros((19617,5))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=feat_cnt, shuffle=True, random_state=23*rnd)\n",
    "    for train_index, test_index in skf.split(train_tfidf,train_Y):\n",
    "        # tfidf to nb\n",
    "        X_train, X_test = train_tfidf[train_index], train_tfidf[test_index]\n",
    "        y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
    "        tmp_model = MultinomialNB(alpha=0.025,fit_prior=False)\n",
    "        tmp_model.fit(X_train,y_train)\n",
    "        tmp_train_feat = tmp_model.predict_proba(X_test)\n",
    "        tmp_test_feat = tmp_model.predict_proba(test_tfidf)\n",
    "        help_tfidf_train[test_index] = tmp_train_feat\n",
    "        help_tfidf_test += tmp_test_feat/feat_cnt\n",
    "\n",
    "        # tfidf to nb\n",
    "        X_train, X_test = train_tfidf2[train_index], train_tfidf2[test_index]\n",
    "        tmp_model = MultinomialNB(0.025,fit_prior=False)\n",
    "        tmp_model.fit(X_train,y_train)\n",
    "        tmp_train_feat = tmp_model.predict_proba(X_test)\n",
    "        tmp_test_feat = tmp_model.predict_proba(test_tfidf2)\n",
    "        help_tfidf_train2[test_index] = tmp_train_feat\n",
    "        help_tfidf_test2 += tmp_test_feat/feat_cnt\n",
    "\n",
    "        # count vec to nb\n",
    "        X_train, X_test = train_cvec[train_index], train_cvec[test_index]\n",
    "        tmp_model = MultinomialNB(0.025,fit_prior=False)\n",
    "        tmp_model.fit(X_train,y_train)\n",
    "        tmp_train_feat = tmp_model.predict_proba(X_test)\n",
    "        tmp_test_feat = tmp_model.predict_proba(test_cvec)\n",
    "        help_cnt1_train[test_index] = tmp_train_feat\n",
    "        help_cnt1_test += tmp_test_feat/feat_cnt\n",
    "\n",
    "        # count vec2 to nb \n",
    "        X_train, X_test = train_cvec2[train_index], train_cvec2[test_index]\n",
    "        tmp_model = MultinomialNB(0.025,fit_prior=False)\n",
    "        tmp_model.fit(X_train,y_train)\n",
    "        tmp_train_feat = tmp_model.predict_proba(X_test)\n",
    "        tmp_test_feat = tmp_model.predict_proba(test_cvec2)\n",
    "        help_cnt2_train[test_index] = tmp_train_feat\n",
    "        help_cnt2_test += tmp_test_feat/feat_cnt\n",
    "    \n",
    "    help_train_feat = np.hstack([help_tfidf_train,help_tfidf_train2,help_cnt1_train,help_cnt2_train])\n",
    "    help_test_feat = np.hstack([help_tfidf_test,help_tfidf_test2,help_cnt1_test,help_cnt2_test])\n",
    "\n",
    "    return help_train_feat,help_test_feat\n",
    "    \n",
    "help_train_feat,help_test_feat = gen_nb_feats(1)\n",
    "help_train_feat2,help_test_feat2 = gen_nb_feats(2)\n",
    "help_train_feat3,help_test_feat3 = gen_nb_feats(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_3 = compare_models(sort = 'AUC', n_select = 3)  # 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import xgboost as xgb\n",
    "from sklearn import ensemble, metrics, model_selection, naive_bayes\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, seed_val=0, child=1, colsample=0.3):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 3\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 5\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = child\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = colsample\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = 2000\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n",
    "    if test_X2 is not None:\n",
    "        xgtest2 = xgb.DMatrix(test_X2)\n",
    "        pred_test_y2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "    \n",
    "pred_lst = []\n",
    "for i in range(len(pred_full_test)):\n",
    "    pred_lst.append(np.argmax(pred_full_test[i]))\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(pred_lst, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
